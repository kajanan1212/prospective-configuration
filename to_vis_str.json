{
    "training_iteration": "training iteration",
    "('iteration',)": "iteration",
    "('inference_rate_amplifier',)": "inference_rate_amplifier",
    "('inference_rate_discount',)": "inference_rate_discount",
    "time_since_restore": "training time",
    "('arm_length',)": "arm_length",
    "('group',)": "group",
    "('error_type',)": "error_type",
    "('error_l',)": "error_l",
    "('gain_lg',)": "gain_lg",
    "('acf_at',)": "acf_at",
    "('acf_at_backward',)": "acf_at_backward",
    "('Re',)": "Re",
    "('R',)": "R",
    "('C',)": "C",
    "('L',)": "L",
    "('P',)": "P",
    "df['x_1'].iloc[-1]": "x_1",
    "df['x_1_change'].iloc[-1]": "x_1_change",
    "df['e_1_change'].iloc[-1]": "e_1_change",
    "df['x_2_unclampped'].iloc[-1]": "x_2_unclampped",
    "('I',)": "I",
    "('D',)": "D",
    "('Amplifier_kwargs', 'voltage_gain')": "voltage_gain",
    "('Amplifier_kwargs', 'input_resistence')": "input_resistence",
    "('Amplifier_kwargs', 'output_resistence')": "output_resistence",
    "eval(df['log-along-t'].iloc[-1])": "log-along-t",
    "('share_output_across_tasks',)": "share_output_across_tasks",
    "('block_error_unused_output',)": "block_error_unused_output",
    "('norm_layer',)": "norm_layer",
    "('num_mms',)": "num_mms",
    "('num_acf',)": "num_acf",
    "('batch_size',)": "batch_size",
    "('experiment_noise_std',)": "experiment_noise_std",
    "('buffer_limit',)": "buffer_limit",
    "('error_on_x_2',)": "error_on_x_2",
    "('gain_coefficient',)": "gain_coefficient",
    "('structure',)": "structure",
    "('input',)": "input",
    "('is_with_negative',)": "is_with_negative",
    "('output',)": "output",
    "('has_input_pc_layer',)": "has_input_pc_layer",
    "('which_weight',)": "which_weight",
    "eval(df['value-along-t'].iloc[-1])": "value-along-t",
    "eval(df['signal-along-t'].iloc[-1])": "signal-along-t",
    "('lr',)": "lr",
    "('mu_1',)": "mu_1",
    "('mu_1_0',)": "mu_1_0",
    "('mu_1_1',)": "mu_1_1",
    "('W_1_0_0',)": "W_1_0_0",
    "('W_1_1_0',)": "W_1_1_0",
    "('number_of_pair',)": "number_of_pair",
    "('target_R',)": "target_R",
    "('direction',)": "direction",
    "('log_l',)": "log_l",
    "('env_size',)": "env_size",
    "('at_iteration',)": "at_iteration",
    "('model', 'model_type_order')": "model_type_order",
    "eval(df['value-along-index'].iloc[-1])": "value-along-index",
    "eval(df['extinction:value_along_index'].iloc[-1])": "value-along-index",
    "('memory_lr',)": "memory_lr",
    "('bias',)": "bias",
    "('learning_rate_layer_decay',)": "learning_rate_layer_decay",
    "df['train__error'].mean()": "Mean of train__error",
    "df['train__error'].min()": "Min of train__error",
    "df['train__classification_error'].mean()": "Mean of train__classification_error",
    "('fit_data_b',)": "fit_data_b",
    "('reward',)": "reward",
    "('target_type',)": "target_type",
    "('fit_data_w',)": "fit_data_w",
    "df['Episode Reward'].max()": "Max of episode reward",
    "('phase',)": "phase",
    "('clamp',)": "clamp",
    "('sync_freq',)": "sync_freq",
    "('target',)": "target",
    "('hidden_i',)": "hidden_i",
    "('constrain_w',)": "constrain_w",
    "('R_switch_off_gain',)": "R_switch_off_gain",
    "('input_amplifier',)": "input_amplifier",
    "('corruption_type',)": "corruption_type",
    "('corruption_degree',)": "corruption_degree",
    "('gamma',)": "gamma",
    "('is_var_pc_layer',)": "is_var_pc_layer",
    "('interval_update_target_q',)": "interval_update_target_q",
    "('num_learn_epochs_per_eposide',)": "num_learn_epochs_per_eposide",
    "('init_std',)": "init_std",
    "('init_offset',)": "init_offset",
    "('num_batch_per_iteration',)": "num_batch_per_iteration",
    "('at',)": "at",
    "('weak_belief',)": "weak_belief",
    "('num_iterations',)": "num_iterations",
    "('weak_association',)": "weak_association",
    "('strong_association',)": "strong_association",
    "('seed',)": "seed",
    "('implementation',)": "implementation",
    "('device',)": "device",
    "('num_repeatations',)": "num_repeatations",
    "('T',)": "MainT",
    "('is_detach_target',)": "is_detach_target",
    "('num_layers',)": "num_layers",
    "('energy_fn_str',)": "energy_fn_str",
    "('hidden_size',)": "hidden_size",
    "('R_e_w_sum_gain',)": "R_e_w_sum_gain",
    "('R_e_w_base_gain',)": "R_e_w_base_gain",
    "('R_w_sum_layer_gain',)": "R_w_sum_layer_gain",
    "('failure_l',)": "failure_l",
    "('partial_num_unlabelled',)": "partial_num_unlabelled",
    "('initial_w',)": "initial_w",
    "('R_mean_gain',)": "R_mean_gain",
    "('r_mean',)": "r_mean",
    "('is_r_switch',)": "is_r_switch",
    "('learn_mode',)": "learn_mode",
    "('loss',)": "loss",
    "('l',)": "l",
    "('i',)": "i",
    "('iteration_end',)": "iteration_end",
    "('unisign_WWs',)": "unisign_WWs",
    "('x_coefficient',)": "x_coefficient",
    "('mu_coefficient',)": "mu_coefficient",
    "('model', 'acf')": "acf",
    "('model', 'ns')": "ns",
    "('model', 'width_scale')": "width_scale",
    "('model', 'bias')": "bias",
    "('model', 'init', 'kwargs', 'gain')": "gain",
    "('model', 'pc_layer_at')": "pc_layer_at",
    "('model', 'layer_kwargs', 'energy_fn_str')": "energy_fn_str",
    "('test_infr', 'l')": "l",
    "('train', 'predictive_coding')": "PC",
    "('acf_kwargs', 'slope')": "slope",
    "('r_fn_kwargs', 'c')": "c",
    "('acf_kwargs', 'scale')": "scale",
    "('predictive_coding',)": "PC",
    "('r_bottom_mode',)": "r_bottom_mode",
    "('loss_fn',)": "loss_fn",
    "('loss_fn_coeff',)": "loss_fn_coeff",
    "('train', 'loss_fn_str')": "loss_fn_str",
    "df['Layer Index'][0]": "Layer Index",
    "df['Network Index'][0]": "Network Index",
    "('train', 'trainer_kwargs', 'x_loss_fn')": "x_loss_fn",
    "df['experiment_tag'].iloc[-1]": "experiment_tag",
    "df['train__target_alignment'].iloc[-1]": "target_alignment",
    "df['train__prospective_index'].iloc[-1]": "prospective_index",
    "df['train__prediction_std'].iloc[-1]": "prediction_std",
    "df['log'].iloc[-1]": "log",
    "df['train__e'].iloc[-1]": "e",
    "df['adaption'].iloc[-1]": "adaption",
    "df['time'].iloc[-1]": "time",
    "df['train__self.neuron_response_mutual_infos_max_mean'].iloc[-1]": "neuron_response_mutual_infos_max_mean",
    "np.mean(df['test__cur-test__error'].dropna())": "error (cur)",
    "('train', 'trainer_kwargs', 'loss_fn_coefficient')": "loss_fn_coefficient",
    "('train', 'trainer_kwargs', 'optimizer_p_fn_str')": "optimizer_p_fn_str",
    "('train', 'trainer_kwargs', 'optimizer_p_kwargs', 'lr')": "learning_rate",
    "('train', 'trainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')": "Weight Decay",
    "('train', 'trainer_kwargs', 'optimizer_x_fn_str')": "optimizer_x_fn_str",
    "('train', 'trainer_kwargs', 'optimizer_x_kwargs', 'lr')": "Inference rate",
    "('train', 'trainer_kwargs', 'update_p_at')": "update_p_at",
    "('train', 'trainer_kwargs', 'train_initial_random_sign')": "train_initial_random_sign",
    "('train', 'trainer_kwargs', 'train_initial_sigma')": "train_initial_sigma",
    "('train', 'trainer_kwargs', 'is_contrastive_learning')": "is_contrastive_learning",
    "('run_dynamic_kwargs', 'learn', 'clamp_kwargs', 'output', 'clamp_to_pre_fn')": "clamp_to_pre_fn",
    "np.mean(df['early_stop'])": "early stop",
    "('test', 'test_by')": "test_by",
    "df['accuracy'].sum()": "sum of accuracy",
    "df['val_ppl'].mean()": "val_ppl-mean",
    "df['value_loss'].mean()": "Mean of value_loss",
    "df['val_ppl'].min()": "val_ppl-min",
    "df['accuracy'].max()": "max of accuracy",
    "('test', 'test_by_data')": "test_by_data",
    "df['train__x'].iloc[-1]": "x",
    "df['train__y'].iloc[-1]": "y",
    "('VNet_kwargs', 'head_energy_fn')": "head_energy_fn",
    "('dataset', 'name')": "dataset",
    "('dataset', 'partial_num')": "Datapoints per class",
    "('dataset', 'data_loader_kwargs', 'shuffle')": "shuffle",
    "('dataset', 'unlabeled_num')": "unlabeled_num",
    "('partial_num',)": "partial_num",
    "('is_Ws_update_with_fprime',)": "is_Ws_update_with_fprime",
    "('is_Ws_update_with_f',)": "is_Ws_update_with_f",
    "('train', 'batch_size')": "Batch Size",
    "df[['results[losses][0]','results[losses][-1]','results[total_losses][0]','results[total_losses][-1]','early_stop','t_c']]": "train_data",
    "('train', 'trainer_kwargs', 'inputs_loss_fn')": "inputs_loss_fn",
    "('measure',)": "measure",
    "('type',)": "type",
    "('num_datapoints',)": "num_datapoints",
    "('iteration_end',)": "iteration_end",
    "('optimizer_inference_fn',)": "optimizer_inference_fn",
    "('optimizer_learning_fn',)": "optimizer_learning_fn",
    "('name',)": "name",
    "('bptt',)": "bptt",
    "('data', 'is_normalize')": "data:is_normalize",
    "('target', 'min')": "target:min",
    "('target', 'max')": "target:max",
    "('TransformerModel_kwargs', 'energy_coefficient')": "energy_coefficient",
    "('TransformerModel_kwargs', 'pc_layer_where')": "pc_layer_where",
    "('TransformerModel_kwargs', 'scaled_dot_product_attention_kwargs', 'similarity_function')": "similarity_function",
    "('TransformerModel_kwargs', 'scaled_dot_product_attention_kwargs', 'beta')": "beta",
    "('log',)": "log",
    "('fr_b',)": "fr_b",
    "('fr_f',)": "fr_f",
    "('w_b',)": "w_b",
    "('w_f',)": "w_f",
    "('train_id',)": "train_id",
    "('optimizer',)": "optimizer",
    "('optimizer_p',)": "optimizer_p",
    "('log_task_i',)": "log_task_i",
    "('sign',)": "sign",
    "('image_arm_length',)": "image_arm_length",
    "('label_arm_length',)": "label_arm_length",
    "('num_input_dendrites',)": "num_input_dendrites",
    "('num_input_dendrites_backward',)": "num_input_dendrites_backward",
    "('dw_other',)": "dw_other",
    "('dendritic_input_fn',)": "dendritic_input_fn",
    "('dendritic_input_fn_backward',)": "dendritic_input_fn_backward",
    "('d_f',)": "d_f",
    "df['train__loss'].iloc[-1]": "train__loss",
    "df['w_1'].iloc[-1]": "w_1",
    "df['w_2'].iloc[-1]": "w_2",
    "df['x_1'].iloc[-1]": "x_1",
    "df['x_2'].iloc[-1]": "x_2",
    "df['fr'].iloc[-1]": "fr",
    "df['train__w_1'].iloc[-1]": "w_1",
    "df['train__w_2'].iloc[-1]": "w_2",
    "df['train__x_1'].iloc[-1]": "x_1",
    "df['train__x_2'].iloc[-1]": "x_2",
    "('negative_rate',)": "negative_rate",
    "('is_adaptive_error_precision',)": "is_adaptive_error_precision",
    "('f_pre',)": "f_pre",
    "('num_forward_dendrites',)": "num_forward_dendrites",
    "('num_backward_dendrites',)": "num_backward_dendrites",
    "('is_fc',)": "is_fc",
    "('f_pre_other',)": "f_pre_other",
    "('is_manual_xs_dynamic',)": "is_manual_xs_dynamic",
    "('init_way',)": "init_way",
    "('init_fn',)": "init_fn",
    "('wws_update_num',)": "wws_update_num",
    "('wws_update_freq',)": "wws_update_freq",
    "('prospective_index_l',)": "prospective_index_l",
    "('train__loss',)": "train__loss",
    "('wws_update_portion',)": "wws_update_portion",
    "('xs_update_portion',)": "xs_update_portion",
    "('xs_update_at',)": "xs_update_at",
    "('Ws_update_with_x',)": "Ws_update_with_x",
    "('init_fn_kwargs', 'gain')": "Gain",
    "('get_recommended_circuit_configs_kwargs', 'R_acf_short')": "R_acf_short",
    "('get_recommended_circuit_configs_kwargs', 'much_smaller')": "much_smaller",
    "('get_recommended_circuit_configs_kwargs', 'Rw_min')": "Rw_min",
    "('get_recommended_circuit_configs_kwargs', 'Rw_max_r_min')": "Rw_max_r_min",
    "('get_recommended_circuit_configs_kwargs', 'W_abs_max')": "W_abs_max",
    "('get_recommended_circuit_configs_kwargs', 'A_amplifier')": "A_amplifier",
    "('get_recommended_circuit_configs_kwargs', 'Rc')": "Rc",
    "('get_recommended_circuit_configs_kwargs', 'max_in_features')": "max_in_features",
    "('get_recommended_circuit_configs_kwargs', 'R_amplifier_base')": "R_amplifier_base",
    "('get_recommended_circuit_configs_kwargs', 'R_amplifier_input')": "R_amplifier_input",
    "('get_recommended_circuit_configs_kwargs', 'Re')": "Re",
    "('get_recommended_circuit_configs_kwargs', 'Ro')": "Ro",
    "('Layer1_kwargs', 'w_2')": "w_2",
    "('Layer1_kwargs', 'w_1')": "w_1",
    "('Layer2_kwargs', 'is_trainable')": "l2_is_trainable",
    "('PCLayer_kwargs', 'beta_first_error_moment')": "beta_1",
    "('PCLayer_kwargs', 'beta_second_error_moment')": "beta_2",
    "('PCLayer_kwargs', 'beta_adaptive_error_precision')": "beta",
    "('PCLayer_kwargs', 'adaptive_error_precision_fn')": "adaptive_error_precision_fn",
    "('xs_init_fn_kwargs', 'std')": "xs_init_std",
    "('train', 'trainer_kwargs', 'T')": "T",
    "('train', 'trainer_kwargs', 'early_stop_conditions')": "early_stop_conditions",
    "('train', 'trainer_kwargs', 'x_lr_discount')": "Inference rate discount",
    "('train', 'trainer_kwargs', 'x_lr_amplifier')": "x_lr_amplifier",
    "('train', 'trainer_kwargs', 'is_sample_x_once')": "is_sample_x_once",
    "('unlabeled_data_fill',)": "unlabeled_data_fill",
    "('run_kwargs', 'stop', 'training_iteration')": "training_iteration",
    "('test', 'test_by_energy_trainer_kwargs', 'optimizer_x_kwargs', 'lr')": "e_x_lr",
    "('test', 'test_by_energy_trainer_kwargs', 'x_lr_discount')": "e_x_lr_discount",
    "('local_mode',)": "local",
    "('learn_output_clamp_on',)": "learn_output_clamp_on",
    "('learn_output_clamp_to_pre_fn',)": "learn_output_clamp_to_pre_fn",
    "df['results[losses][-1]'].iloc[1:].to_numpy()": "train_loss",
    "df['results[losses][-1]'].iloc[1:].sum(skipna=False)": "sum of loss",
    "df['results[losses][-1]'].iloc[1:].mean()": "Mean of Loss",
    "df['results[losses][-1]'].iloc[1:].iloc[-1]": "last_train_loss",
    "df['results[losses][-1]'].to_numpy()": "train_loss",
    "df['results[losses][-1]'].sum(skipna=False)": "sum_train_loss",
    "df['results[losses][-1]'].iloc[-1]": "last_train_loss",
    "df['test__cur-test__error'].to_numpy()": "test__cur-test__error",
    "df['test__cur-test__error'].sum(skipna=False)": "sum_test__cur-test__error",
    "df['test__cur-test__error'].iloc[-1]": "last_test__cur-test__error",
    "df['test__all-test__error'].to_numpy()": "test__all-test__error",
    "df['test__all-test__error'].sum(skipna=False)": "sum_test__all-test__error",
    "df['test__all-test__error'].iloc[-1]": "last_test__all-test__error",
    "test__test_split__error": "test error",
    "df['test__test_split__error'].to_numpy()": "test__test_split__error",
    "df['test__test_split__error'].sum(skipna=False)": "Sum of test__classification_error",
    "df['test__test_split__error'].mean(skipna=False)": "Mean of test__classification_error",
    "df['test__test_split__error'].sum()": "Sum of test__classification_error",
    "df['test__test_split__error'].iloc[-1]": "last_test__test_split__error",
    "df['test__test_split__error'].min()": "Min of test__classification_error",
    "df['test__test_split__error'].mean()": "Mean of test__classification_error",
    "df['training_iteration'].max()": "max training iteration",
    "('rule',)": "Rule",
    "('tag',)": "Rule",
    "('pc_at',)": "pc_at",
    "('learning_rate',)": "learning_rate",
    "('Ws_update_at',)": "Ws_update_at",
    "('experiment',)": "Experiment",
    "('learning_rate_error',)": "learning_rate_error",
    "('inference_rate',)": "Inference rate",
    "('inference_duration',)": "Inference duration",
    "df['Ws_delta_str'].iloc[-1]": "Ws_delta_str",
    "df['d_w'].iloc[-1]": "d_w",
    "('log_W',)": "log_W",
    "('map_w',)": "map_w",
    "('W',)": "W",
    "('is_preserve_transpose',)": "is_preserve_transpose",
    "('is_preserve_weights_sign',)": "is_preserve_weights_sign",
    "('log_packs', 'W', 'log')": "log_W",
    "df['train__correction_rate'].iloc[-1]": "Correction rate",
    "df['train__correction_rate_in_layer'].iloc[-1]": "Correction rate",
    "df['train__correction_rate'].iloc[0]": "Correction rate",
    "('failure_l',)": "failure_l",
    "df['train__loss'].mean()": "Mean of train__loss",
    "df['test__loss'].mean()": "test__loss:mean",
    "df['train__correction_rate'].mean()": "mean of correction_rate",
    "eval(df['train__w-along-n'].iloc[-1])": "w-along-n",
    "eval(df['train__weight-along-j'].iloc[-1])": "weight-along-j",
    "eval(df['train__energies_history-along-inference_step'].iloc[-1])": "energies_history-along-inference_step",
    "df['train__avg_A_loss'].iloc[-1]": "avg_A_loss",
    "df['train__avg_B_loss'].iloc[-1]": "avg_B_loss",
    "df['train__avg_B_loss-div-avg_A_loss'].iloc[-1]": "avg_B_loss-div-avg_A_loss",
    "df['extinction:index'].iloc[-1]": "index",
    "df['extinction:error'].iloc[-1]": "Data-Prediction Error",
    "df['extinction:Np'].iloc[-1]": "Np",
    "df['extinction:LNp_Ln'].iloc[-1]": "LNp_Ln",
    "df['extinction:LNp'].iloc[-1]": "LNp",
    "('k',)": "k",
    "('init_same_sign',)": "init_same_sign",
    "('b',)": "b",
    "('H',)": "H",
    "('log_id',)": "log_id",
    "('R_w_fix_rate',)": "R_w_fix_rate",
    "('L',)": "L",
    "('N',)": "N",
    "('num_s_in',)": "num_s_in",
    "('tone_strength',)": "tone_strength",
    "('weight_decay_norm',)": "weight_decay_norm",
    "('weight_decay',)": "weight_decay",
    "df['train__loss_0_1'].iloc[-1]": "loss_0_1",
    "df['train__W0W1'].iloc[-1]": "W0W1",
    "df['W0W1'].iloc[-1]": "W0W1",
    "('log_packs', 'W', 'log')": "W",
    "df['train__error'].iloc[-1]": "Average Error on Non-correcting Neuros",
    "df['extinction__fear_to_N'].iloc[-1]": "fear_to_N",
    "df['train__branching_rate'].iloc[-1]": "Branching Rate",
    "('n',)": "M",
    "('neuron_response_of',)": "neuron_response_of",
    "('branch',)": "Branch",
    "('L_lr',)": "L_lr",
    "('N_lr',)": "N_lr",
    "('perception_lr',)": "perception_lr",
    "('MN',)": "MN",
    "('M',)": "M",
    "('init_W0',)": "init_W0",
    "('x_0',)": "x_0",
    "('x_1',)": "x_1",
    "('dropout_p',)": "dropout_p",
    "('x_1_level',)": "x_1_level",
    "('loss_level',)": "loss_level",
    "df['x_0_level'].iloc[-1]": "x_0_level",
    "('is_norm_obs',)": "is_norm_obs",
    "('stochastic_inference_std',)": "stochastic_inference_std",
    "('is_manual_init_w1',)": "is_manual_init_w1",
    "('is_norm_rew',)": "is_norm_rew",
    "('acf',)": "acf",
    "('force_Ws_backward',)": "force_Ws_backward",
    "('error_coefficient',)": "error_coefficient",
    "('mean_forward_coefficient',)": "mean_forward_coefficient",
    "('acf_backward',)": "acf_backward",
    "('restrict_Ws_sign',)": "restrict_Ws_sign",
    "('dataset',)": "Dataset",
    "('is_predict_after_inference',)": "is_predict_after_inference",
    "('max_t',)": "max_t",
    "('signal_id',)": "signal_id",
    "('acf_scale',)": "acf_scale",
    "('scale',)": "scale",
    "('is_update_Ws_backward',)": "is_update_Ws_backward",
    "df['loss'].iloc[-1]": "loss",
    "eval(df['current_signal-along-voltage_signal'].iloc[-1])": "current_signal-along-voltage_signal",
    "df['train__hidden_neuron_activation_change'].iloc[-1]": "Change of Hidden Neuron Activation",
    "('optimizer_kwargs', 'lr')": "lr",
    "('optimizer_learning_kwargs', 'lr')": "learning_rate",
    "('optimizer_inference_kwargs', 'lr')": "Inference rate",
    "('memristor_kwargs', 'r_off')": "r_off",
    "('memristor_kwargs', 'r_on')": "r_on",
    "('memristor_kwargs', 'alpha_on')": "alpha_on",
    "('PCTrainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')": "weight_decay",
    "('PCTrainer_kwargs', 'optimizer_p_kwargs', 'lr')": "pc_learning_rate",
    "('PCTrainer_kwargs', 'optimizer_x_kwargs', 'lr')": "Inference rate",
    "('PCTrainer_kwargs', 'optimizer_x_kwargs', 'weight_decay')": "Inference weight_decay",
    "('PCTrainer_kwargs', 'T')": "T",
    "('PCTrainer_kwargs', 'optimizer_p_fn')": "Optimizer for learn",
    "('ThreeQModule_kwargs', 'acf_forward')": "acf_forward",
    "('ThreeQModule_kwargs', 'acf_backward')": "acf_backward",
    "('PCTrainer_kwargs', 'optimizer_x_fn')": "Optimizer for inference",
    "('PCTrainer_kwargs', 'x_lr_discount')": "x_lr_discount",
    "('PCTrainer_kwargs', 'x_lr_amplifier')": "x_lr_amplifier",
    "('PCTrainer_kwargs', 'update_p_at')": "update_p_at",
    "df['train__overall'].iloc[-1]": "train_overall_last",
    "df['train__overall'].mean()": "train_overall_mean",
    "df['error'].iloc[-1]": "error",
    "df['trail1_error'].iloc[-1]": "trail1_error",
    "df['trail2_error'].iloc[-1]": "trail2_error",
    "df['prediction'].iloc[-1]": "prediction",
    "df['train__data_weight'].iloc[-1]": "data_weight",
    "df['mu_2'].iloc[-1]": "mu_2",
    "df['x_2'].iloc[-1]": "x_2",
    "df['ECE'].iloc[-1]": "Last of ECE",
    "df['MCE'].iloc[-1]": "Last of MCE",
    "df['test__classification_error'].iloc[-1]": "Last of test__classification_error",
    "df['test__classification_error'].iloc[0]": "First of test__classification_error",
    "df['test__classification_error'].min()": "Min of test__classification_error",
    "df['train__loss'].min()": "Min of train__loss",
    "df['train__loss'].mean()": "Mean of train__loss",
    "df['test__loss'].min()": "Min of test__loss",
    "df['test__classification_error'].mean()": "Mean of test__classification_error",
    "df['test__classification_error'][:84].mean()": "Mean of test__classification_error",
    "df['test__classification_error'].sum()": "Sum of test__classification_error",
    "df['consistency'].iloc[-1]": "consistency",
    "df['trace_rate'].iloc[-1]": "trace_rate",
    "df['measure_result'].iloc[-1]": "measure_result",
    "df['traj_length'].iloc[-1]": "traj_length",
    "df['final_length'].iloc[-1]": "final_length",
    "('ratio_unlabelled_datapoints',)": "Ratio unlabelled datapoints",
    "('ns',)": "ns",
    "('lr',)": "lr",
    "('R_if_1',)": "R_if_1",
    "('R_if_2',)": "R_if_2",
    "('env',)": "env",
    "('G_w_p_1',)": "G_w_p_1",
    "('G_w_n_1',)": "G_w_n_1",
    "('x_2',)": "x_2",
    "('buffer_limit',)": "buffer_limit",
    "('is_r_normalize',)": "is_r_normalize",
    "('is_s_normalize',)": "is_s_normalize",
    "('Qnet_kwargs', 'acf_fn')": "acf_fn",
    "('Qnet_kwargs', 'acf')": "acf",
    "('Qnet_kwargs', 'bias')": "bias",
    "('Qnet_kwargs', 'pc_layer_at')": "pc_layer_at",
    "('l',)": "l",
    "('learning_duration',)": "learning_duration",
    "('pc_layer_at',)": "pc_layer_at",
    "('x2',)": "x2",
    "('w1',)": "w1",
    "('w2',)": "w2",
    "df['train__e_next'].iloc[-1]": "e_next",
    "df['train__x_e_next'].iloc[-1]": "x_e_next",
    "('model', 'custom_model_config', 'PC')": "PC",
    "('energy_at',)": "Energy At",
    "df['Episode Reward'].mean()": "Mean of episode reward",
    "df['train__prospective_index'].mean()": "Prospective index",
    "df['train__error_delta_sign'].mean()": "Mean of Error Delta Sign",
    "('energy_fn',)": "Energy function",
    "('is_with_negative_phase',)": "Is With Negative Phase",
    "('connectivity',)": "Connectivity",
    "('env',)": "Env",
    "('is_q_target',)": "is_q_target",
    "('weight_dynamic',)": "Weight Dynamic",
    "('optimizer_xs_kwargs', 'lr')": "Inference rate",
    "('optimizer_Ws_kwargs', 'lr')": "learning_rate"
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Drive"
      ],
      "metadata": {
        "id": "WZfwtBUfxug8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "PSeIIb1bxZFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xspzJjbaxcRO",
        "outputId": "e08296fa-2ce0-4223-983e-aea15bd591d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Git"
      ],
      "metadata": {
        "id": "t_RC7PCUxqg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install --skip-smudge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WldJa50sxUW",
        "outputId": "47bb63a4-0de0-48d9-b0ff-5fb1bf5ca3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6_WlrPOIW6x",
        "outputId": "6939a75a-174f-4216-c637-27a893eb2bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'prospective-configuration'...\n",
            "remote: Enumerating objects: 4039, done.\u001b[K\n",
            "remote: Counting objects: 100% (1161/1161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (888/888), done.\u001b[K\n",
            "remote: Total 4039 (delta 277), reused 1109 (delta 266), pack-reused 2878\u001b[K\n",
            "Receiving objects: 100% (4039/4039), 371.10 MiB | 24.97 MiB/s, done.\n",
            "Resolving deltas: 100% (1705/1705), done.\n",
            "Updating files: 100% (3173/3173), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kajanan1212/prospective-configuration.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6fJxZSvI3v7",
        "outputId": "d9016b03-c36a-4629-f742-4ea8050c4325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  prospective-configuration  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp57hnvUKRJ4",
        "outputId": "33e3e750-274e-4ce5-bf39-51bed6dff541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/prospective-configuration\n"
          ]
        }
      ],
      "source": [
        "%cd prospective-configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u4donMWKgLD",
        "outputId": "56a1f05f-d280-4ecf-de7f-5a83044d9ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analysis_utils.py\t\tDockerfile\t\t       predictive_coding\n",
            "analysis_v1.py\t\t\texperiments\t\t       README.md\n",
            "any_energy_trainable_legacy.py\tfit_data.py\t\t       source_data\n",
            "any_energy_trainable.py\t\thand_coded_rules_trainable.py  supervised_learning_trainable.py\n",
            "base_trainable.py\t\tinterfere.png\t\t       to_vis_str.json\n",
            "dataset_learning_trainable.py\tLICENSE\t\t\t       utils.py\n",
            "dataset_utils.py\t\tmain.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cytKk7bMvMo",
        "outputId": "0ac03fb4-e1d1-4e64-a0b7-4288e5c5af49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating files: 100% (786/786), done.\n",
            "Branch 'kajanan/create-experiments-folder-for-aai' set up to track remote branch 'kajanan/create-experiments-folder-for-aai' from 'origin'.\n",
            "Switched to a new branch 'kajanan/create-experiments-folder-for-aai'\n"
          ]
        }
      ],
      "source": [
        "!git checkout \"kajanan/create-experiments-folder-for-aai\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements"
      ],
      "metadata": {
        "id": "fVTXzU0yxmSZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmWW2fTLK8W5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fac8db-2a8e-4952-8b22-db1c7a8e7629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting comet_ml (from -r requirements.txt (line 1))\n",
            "  Downloading comet_ml-3.43.2-py3-none-any.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.4/677.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (6.0.1)\n",
            "Collecting ray (from -r requirements.txt (line 5))\n",
            "  Downloading ray-2.31.0-cp310-cp310-manylinux2014_x86_64.whl (66.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.11.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.13.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.66.4)\n",
            "Collecting visdom (from -r requirements.txt (line 13))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from -r requirements.txt (line 14))\n",
            "  Downloading wandb-0.17.3-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml->-r requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml->-r requirements.txt (line 1)) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version>=2.8.0 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading sentry_sdk-2.7.1-py2.py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml->-r requirements.txt (line 1)) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml->-r requirements.txt (line 1)) (13.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->-r requirements.txt (line 3)) (8.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly->-r requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (3.15.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests->-r requirements.txt (line 6)) (2024.6.2)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 10)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 13)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 13)) (1.16.0)\n",
            "Collecting jsonpatch (from visdom->-r requirements.txt (line 13))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom->-r requirements.txt (line 13)) (1.8.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 14))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 14))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (4.2.2)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 14))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 14)) (67.7.2)\n",
            "Collecting tensorboardX>=1.9 (from ray->-r requirements.txt (line 5))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray->-r requirements.txt (line 5)) (14.0.2)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml->-r requirements.txt (line 1))\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml->-r requirements.txt (line 1)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml->-r requirements.txt (line 1)) (0.18.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn->-r requirements.txt (line 8)) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 10)) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom->-r requirements.txt (line 13))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 10)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 14))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml->-r requirements.txt (line 1)) (0.1.2)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=b36a88818030a038209561adfc274caa1b87837a819a67084fbc71b00bcbae37\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: everett, wurlitzer, tensorboardX, smmap, simplejson, setproctitle, sentry-sdk, semantic-version, python-box, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonpointer, dulwich, docker-pycreds, configobj, requests-toolbelt, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jsonpatch, gitdb, visdom, nvidia-cusolver-cu12, gitpython, wandb, ray, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.2.0\n",
            "    Uninstalling python-box-7.2.0:\n",
            "      Successfully uninstalled python-box-7.2.0\n",
            "Successfully installed comet_ml-3.43.2 configobj-5.0.8 docker-pycreds-0.4.0 dulwich-0.22.1 everett-3.1.0 gitdb-4.0.11 gitpython-3.1.43 jsonpatch-1.33 jsonpointer-3.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 python-box-6.1.0 ray-2.31.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.7.1 setproctitle-1.3.3 simplejson-3.19.2 smmap-5.0.1 tensorboardX-2.6.2.2 visdom-0.2.4 wandb-0.17.3 wurlitzer-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Env var"
      ],
      "metadata": {
        "id": "fjFfTFn-xcS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "exp_name = \"09-tl-03\"\n",
        "results_path = \"/content/drive/MyDrive/colab-docs/advanced-ai/results\"\n",
        "data_path = \"/content/prospective-configuration/data\"\n",
        "\n",
        "os.environ['RESULTS_DIR'] = results_path\n",
        "os.environ['DATA_DIR'] = data_path\n",
        "\n",
        "os.environ['EXP_NAME'] = exp_name\n",
        "os.environ['MODEL_DIR'] = f\"{results_path}/{exp_name}/model\"\n",
        "os.environ['ANALYSIS_DIR'] = f\"{results_path}/{exp_name}/analysis\"\n",
        "\n",
        "os.environ['PT_MODEL_DIR'] = f\"{results_path}/08-pt-final/model\""
      ],
      "metadata": {
        "id": "Gh0M7Vr46rLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p $MODEL_DIR"
      ],
      "metadata": {
        "id": "ukMhs-IZK-eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p $ANALYSIS_DIR"
      ],
      "metadata": {
        "id": "jTZhvkxSK_O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base RBP"
      ],
      "metadata": {
        "id": "KOGsjNONxQlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNdKJulvNDrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c838e8b9-4874-4d60-ffec-6d4011534a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now. \n",
            "\n",
            "\n",
            "\n",
            "# WARNING (__main__): parsing <num_cpus> from str has been depreciated, removing now. \n",
            "\n",
            "2024-06-30 17:55:08,617\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\n",
            "# WARNING (__main__): ray_paradigm not specified, defaulting to 'run'. It is recommended to specify this. \n",
            "\n",
            "\n",
            "# WARNING (__main__): the recommended workflow is to use eu.Trainable as your <trainable> or <run_or_experiment>, where eu is imported automatically for your from <your_experiment/utils.py>. But `import experiments.03-del.utils as eu` fails with the following error: \n",
            "invalid syntax (<string>, line 1) \n",
            "\n",
            "\n",
            "# WARNING (__main__): the recommended workflow is to use eu.Trainable as your <run_or_experiment>, where eu is imported automatically for your from <your_experiment/utils.py>. But you are using a custom <run_or_experiment>: SupervisedLearningTrainable\n",
            "\n",
            "╭────────────────────────────────────────────────────────╮\n",
            "│ Configuration for experiment     03-del                │\n",
            "├────────────────────────────────────────────────────────┤\n",
            "│ Search algorithm                 BasicVariantGenerator │\n",
            "│ Scheduler                        FIFOScheduler         │\n",
            "│ Number of trials                 4                     │\n",
            "╰────────────────────────────────────────────────────────╯\n",
            "\n",
            "View detailed results here: /content/drive/MyDrive/colab-docs/advanced-ai/results/03-del\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts`\n",
            "\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2024-06-30 17:55:12. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       PCTrainer_kwargs/T     ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_e49ae_00000   PENDING    1482555873   False                                   16                   0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00001   PENDING    1482555873   False                                   16                   0.01                       0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00002   PENDING    1482555873   False                                   16                   0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00003   PENDING    1482555873   False                                   16                   0.0001                     0.01 │\n",
            "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "2024-06-30 17:55:26,911\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_e49ae_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42471, ip=172.28.0.12, actor_id=b37ac3c535f039ac04a5499201000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x780a1ef6c370>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_e49ae_00000 errored after 0 iterations at 2024-06-30 17:55:26. Total running time: 15s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00000_0_T=16,lr=0.1000,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42471, ip=172.28.0.12, actor_id=b37ac3c535f039ac04a5499201000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x780a1ef6c370>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m MODEL parameters:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m <generator object Module.parameters at 0x780a1ed13a00>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m MODEL parameters:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m MODEL ARCHITECTURE:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m Sequential(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (1): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (4): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (7): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (9): Flatten(start_dim=1, end_dim=-1)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (10): Linear(in_features=4096, out_features=512, bias=True)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (11): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m   (12): Linear(in_features=512, out_features=10, bias=True)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42471)\u001b[0m )\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   (9): Flatten(start_dim=1, end_dim=-1)\n",
            "2024-06-30 17:55:27,062\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_e49ae_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42482, ip=172.28.0.12, actor_id=6c8d26025f11ddab69bbd22801000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7df0c43d82e0>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_e49ae_00001 errored after 0 iterations at 2024-06-30 17:55:27. Total running time: 15s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00001_1_T=16,lr=0.0100,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt\n",
            "\n",
            "Trial status: 2 ERROR | 2 PENDING\n",
            "Current time: 2024-06-30 17:55:42. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       PCTrainer_kwargs/T     ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_e49ae_00002   PENDING    1482555873   False                                   16                   0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00003   PENDING    1482555873   False                                   16                   0.0001                     0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00000   ERROR      1482555873   False                                   16                   0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00001   ERROR      1482555873   False                                   16                   0.01                       0.01 │\n",
            "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42482, ip=172.28.0.12, actor_id=6c8d26025f11ddab69bbd22801000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7df0c43d82e0>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42482)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42677, ip=172.28.0.12, actor_id=b2f4ac3c94d5fe2dca048ea801000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7cbdc5d64310>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   (9): Flatten(start_dim=1, end_dim=-1)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m MODEL parameters:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m <generator object Module.parameters at 0x7cbdc5b03a00>\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m MODEL ARCHITECTURE:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m Sequential(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   (11): ReLU()\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m   (12): Linear(in_features=512, out_features=10, bias=True)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42677)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "2024-06-30 17:55:45,402\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_e49ae_00002\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42677, ip=172.28.0.12, actor_id=b2f4ac3c94d5fe2dca048ea801000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7cbdc5d64310>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_e49ae_00002 errored after 0 iterations at 2024-06-30 17:55:45. Total running time: 33s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00002_2_T=16,lr=0.0010,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt\n",
            "2024-06-30 17:55:45,744\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_e49ae_00003\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42683, ip=172.28.0.12, actor_id=af73ac84a2ff3ae022ec96bf01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7e26bd3ac3d0>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_e49ae_00003 errored after 0 iterations at 2024-06-30 17:55:45. Total running time: 33s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00003_3_T=16,lr=0.0001,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   (9): Flatten(start_dim=1, end_dim=-1)\n",
            "2024-06-30 17:55:45,860\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/colab-docs/advanced-ai/results/03-del' in 0.1104s.\n",
            "\n",
            "Trial status: 4 ERROR\n",
            "Current time: 2024-06-30 17:55:45. Total running time: 34s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "╭────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       PCTrainer_kwargs/T     ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_e49ae_00000   ERROR      1482555873   False                                   16                   0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00001   ERROR      1482555873   False                                   16                   0.01                       0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00002   ERROR      1482555873   False                                   16                   0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_e49ae_00003   ERROR      1482555873   False                                   16                   0.0001                     0.01 │\n",
            "╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "Number of errored trials: 4\n",
            "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                  # failures   error file                                                                                                                                                                                                                                                 │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_e49ae_00000              1   /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00000_0_T=16,lr=0.1000,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt │\n",
            "│ SupervisedLearningTrainable_e49ae_00001              1   /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00001_1_T=16,lr=0.0100,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt │\n",
            "│ SupervisedLearningTrainable_e49ae_00002              1   /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00002_2_T=16,lr=0.0010,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt │\n",
            "│ SupervisedLearningTrainable_e49ae_00003              1   /tmp/ray/session_2024-06-30_17-55-05_161954_42195/artifacts/2024-06-30_17-55-10/03-del/driver_artifacts/SupervisedLearningTrainable_e49ae_00003_3_T=16,lr=0.0001,weight_decay=0.0100,predictive_coding=False,seed=1482555873_2024-06-30_17-55-11/error.txt │\n",
            "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/prospective-configuration/main.py\", line 206, in <module>\n",
            "    analysis = ray.tune.run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\", line 1035, in run\n",
            "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
            "ray.tune.error.TuneError: ('Trials did not complete', [SupervisedLearningTrainable_e49ae_00000, SupervisedLearningTrainable_e49ae_00001, SupervisedLearningTrainable_e49ae_00002, SupervisedLearningTrainable_e49ae_00003])\n",
            "\u001b[0m\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m MODEL parameters:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m <generator object Module.parameters at 0x7e26bd153a00>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m MODEL ARCHITECTURE:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m Sequential(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   (11): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   (12): Linear(in_features=512, out_features=10, bias=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m )\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=42683, ip=172.28.0.12, actor_id=af73ac84a2ff3ae022ec96bf01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7e26bd3ac3d0>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=42683)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ],
      "source": [
        "!python main.py -c $EXP_NAME/base-rbp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base PPC"
      ],
      "metadata": {
        "id": "dSIBZQrHxWNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -c $EXP_NAME/base-ppc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-PMWnnN1NFA",
        "outputId": "15bfaf18-9ce0-4bb7-da21-c195ae55da01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now. \n",
            "\n",
            "\n",
            "\n",
            "# WARNING (__main__): parsing <num_cpus> from str has been depreciated, removing now. \n",
            "\n",
            "2024-06-30 17:56:55,706\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\n",
            "# WARNING (__main__): ray_paradigm not specified, defaulting to 'run'. It is recommended to specify this. \n",
            "\n",
            "\n",
            "# WARNING (__main__): the recommended workflow is to use eu.Trainable as your <trainable> or <run_or_experiment>, where eu is imported automatically for your from <your_experiment/utils.py>. But `import experiments.03-del.utils as eu` fails with the following error: \n",
            "invalid syntax (<string>, line 1) \n",
            "\n",
            "\n",
            "# WARNING (__main__): the recommended workflow is to use eu.Trainable as your <run_or_experiment>, where eu is imported automatically for your from <your_experiment/utils.py>. But you are using a custom <run_or_experiment>: SupervisedLearningTrainable\n",
            "\n",
            "╭────────────────────────────────────────────────────────╮\n",
            "│ Configuration for experiment     03-del                │\n",
            "├────────────────────────────────────────────────────────┤\n",
            "│ Search algorithm                 BasicVariantGenerator │\n",
            "│ Scheduler                        FIFOScheduler         │\n",
            "│ Number of trials                 4                     │\n",
            "╰────────────────────────────────────────────────────────╯\n",
            "\n",
            "View detailed results here: /content/drive/MyDrive/colab-docs/advanced-ai/results/03-del\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts`\n",
            "\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2024-06-30 17:56:58. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_246c1_00000   PENDING    1482555873   True                                  0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00001   PENDING    1482555873   True                                  0.01                       0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00002   PENDING    1482555873   True                                  0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00003   PENDING    1482555873   True                                  0.0001                     0.01 │\n",
            "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "2024-06-30 17:57:14,004\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_246c1_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43345, ip=172.28.0.12, actor_id=f54904d9a25fde9a0443766001000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7b2f2da44370>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_246c1_00000 errored after 0 iterations at 2024-06-30 17:57:14. Total running time: 16s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00000_0_lr=0.1000,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43345, ip=172.28.0.12, actor_id=f54904d9a25fde9a0443766001000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7b2f2da44370>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m MODEL parameters:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m <generator object Module.parameters at 0x7b2f2d9fba00>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m MODEL parameters:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m MODEL ARCHITECTURE:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m Sequential(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (1): PCLayer()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (2): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (5): PCLayer()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (6): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (9): PCLayer()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (10): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (12): Flatten(start_dim=1, end_dim=-1)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (13): Linear(in_features=4096, out_features=512, bias=True)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (14): PCLayer()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (15): ReLU()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m   (16): Linear(in_features=512, out_features=10, bias=True)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43345)\u001b[0m )\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   (12): Flatten(start_dim=1, end_dim=-1)\n",
            "2024-06-30 17:57:14,077\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_246c1_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43346, ip=172.28.0.12, actor_id=6c02b7ea5600b9d41accd6a101000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7a63168943a0>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_246c1_00001 errored after 0 iterations at 2024-06-30 17:57:14. Total running time: 16s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00001_1_lr=0.0100,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt\n",
            "\n",
            "Trial status: 2 ERROR | 2 PENDING\n",
            "Current time: 2024-06-30 17:57:28. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_246c1_00002   PENDING    1482555873   True                                  0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00003   PENDING    1482555873   True                                  0.0001                     0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00000   ERROR      1482555873   True                                  0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00001   ERROR      1482555873   True                                  0.01                       0.01 │\n",
            "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43346, ip=172.28.0.12, actor_id=6c02b7ea5600b9d41accd6a101000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7a63168943a0>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43346)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (12): Flatten(start_dim=1, end_dim=-1)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m MODEL parameters:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m <generator object Module.parameters at 0x7cad0b9cba00>\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m MODEL ARCHITECTURE:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m Sequential(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (14): PCLayer()\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (15): ReLU()\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   (16): Linear(in_features=512, out_features=10, bias=True)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m )\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "2024-06-30 17:57:32,507\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_246c1_00003\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43554, ip=172.28.0.12, actor_id=194f64c56b46200ad39b18ff01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7cad0bc2c3a0>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_246c1_00003 errored after 0 iterations at 2024-06-30 17:57:32. Total running time: 34s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00003_3_lr=0.0001,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43554, ip=172.28.0.12, actor_id=194f64c56b46200ad39b18ff01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7cad0bc2c3a0>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43554)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "2024-06-30 17:57:32,656\tERROR tune_controller.py:1331 -- Trial task failed for trial SupervisedLearningTrainable_246c1_00002\n",
            "Traceback (most recent call last):\n",
            "  File \"python/ray/_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py\", line 691, in actor_method_executor\n",
            "    return method(__ray_actor, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py\", line 467, in _resume_span\n",
            "    return method(self, *_args, **_kwargs)\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2639, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 866, in get_objects\n",
            "    raise value\n",
            "  File \"python/ray/_raylet.pyx\", line 2288, in ray._raylet.task_execution_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 2184, in ray._raylet.execute_task_with_cancellation_handler\n",
            "  File \"python/ray/_raylet.pyx\", line 1839, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1840, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 2078, in ray._raylet.execute_task\n",
            "  File \"python/ray/_raylet.pyx\", line 1105, in ray._raylet.store_task_errors\n",
            "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43552, ip=172.28.0.12, actor_id=f43f860e16d16cba6315ec8e01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7be8dcdd43a0>)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "    self.setup(copy.deepcopy(self.config))\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "    self.reset_model()\n",
            "  File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "    exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "  File \"<string>\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 779, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "    return t.to(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n",
            "\n",
            "Trial SupervisedLearningTrainable_246c1_00002 errored after 0 iterations at 2024-06-30 17:57:32. Total running time: 34s\n",
            "Error file: /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00002_2_lr=0.0010,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m 7\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([64, 3, 5, 5])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([128, 64, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([256, 128, 3, 3])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([512, 4096])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([10, 512])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m torch.Size([10])\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (12): Flatten(start_dim=1, end_dim=-1)\n",
            "2024-06-30 17:57:32,751\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/content/drive/MyDrive/colab-docs/advanced-ai/results/03-del' in 0.0900s.\n",
            "\n",
            "Trial status: 4 ERROR\n",
            "Current time: 2024-06-30 17:57:32. Total running time: 34s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                status           seed   predictive_coding       ...mizer_p_kwargs/lr     ...args/weight_decay │\n",
            "├─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_246c1_00000   ERROR      1482555873   True                                  0.1                        0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00001   ERROR      1482555873   True                                  0.01                       0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00002   ERROR      1482555873   True                                  0.001                      0.01 │\n",
            "│ SupervisedLearningTrainable_246c1_00003   ERROR      1482555873   True                                  0.0001                     0.01 │\n",
            "╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "Number of errored trials: 4\n",
            "╭───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
            "│ Trial name                                  # failures   error file                                                                                                                                                                                                                                           │\n",
            "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
            "│ SupervisedLearningTrainable_246c1_00000              1   /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00000_0_lr=0.1000,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt │\n",
            "│ SupervisedLearningTrainable_246c1_00001              1   /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00001_1_lr=0.0100,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt │\n",
            "│ SupervisedLearningTrainable_246c1_00002              1   /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00002_2_lr=0.0010,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt │\n",
            "│ SupervisedLearningTrainable_246c1_00003              1   /tmp/ray/session_2024-06-30_17-56-51_867920_43066/artifacts/2024-06-30_17-56-57/03-del/driver_artifacts/SupervisedLearningTrainable_246c1_00003_3_lr=0.0001,weight_decay=0.0100,predictive_coding=True,seed=1482555873_2024-06-30_17-56-57/error.txt │\n",
            "╰───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/prospective-configuration/main.py\", line 206, in <module>\n",
            "    analysis = ray.tune.run(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\", line 1035, in run\n",
            "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
            "ray.tune.error.TuneError: ('Trials did not complete', [SupervisedLearningTrainable_246c1_00000, SupervisedLearningTrainable_246c1_00001, SupervisedLearningTrainable_246c1_00002, SupervisedLearningTrainable_246c1_00003])\n",
            "\u001b[0m\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m MODEL parameters:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m <generator object Module.parameters at 0x7be8dcb73a00>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m MODEL ARCHITECTURE:\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m Sequential(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (14): PCLayer()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (15): ReLU()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   (16): Linear(in_features=512, out_features=10, bias=True)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m )\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m # WARNING (dataset_learning_trainable): before_DatasetLearningTrainable_creating_data_packs_code is not specified, but before_DatasetLearningTrainable_setup_code is specified. use before_DatasetLearningTrainable_setup_code instead as before_DatasetLearningTrainable_creating_data_packs_code for backward compatibility. Move your code for creating data_packs to before_DatasetLearningTrainable_creating_data_packs_code in the future. \n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m # WARNING (dataset_utils): partial_dateset is deprecated, use partial_dataset_v1 instead.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 804, in _apply\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SupervisedLearningTrainable.__init__()\u001b[39m (pid=43552, ip=172.28.0.12, actor_id=f43f860e16d16cba6315ec8e01000000, repr=<supervised_learning_trainable.SupervisedLearningTrainable object at 0x7be8dcdd43a0>)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 39, in setup\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     self.reset_model()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/content/prospective-configuration/supervised_learning_trainable.py\", line 45, in reset_model\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     exec(self.config.get(\"model_creation_code\", \"pass\"))\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"<string>\", line 10, in <module>\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1173, in to\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     return self._apply(convert)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     module._apply(fn)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     param_applied = fn(param)\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1159, in convert\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     return t.to(\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m   File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 293, in _lazy_init\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m     torch._C._cuda_init()\n",
            "\u001b[36m(SupervisedLearningTrainable pid=43552)\u001b[0m RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis"
      ],
      "metadata": {
        "id": "QH3r3q7qwxL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"base-min\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"df['test__classification_error'].min()\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-i \\\n",
        "--source-include-columns Rule seed pc_learning_rate \"Min of test__classification_error\" \\\n",
        "--source-columns-rename '{\"pc_learning_rate\": \"learning rate\"}' \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"g=au.nature_relplot(data=df,y='Min of test__classification_error',x='pc_learning_rate',hue='Rule',style='Rule', height=5, aspect=1).set(xscale='log').set_titles('Learning Rate vs Test Classification Error').set_axis_labels('Learning Rate','Test Classification Error',fontsize=10).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"g.set_xticklabels(size=14)\" \\\n",
        "\"g.set_yticklabels(size=14)\" \\\n",
        "\"plt.savefig('fig4-i.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqt0LfuGRdlh",
        "outputId": "41845484-2ccf-4322-b82d-53c97f8d8ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: base-min; UID: 74075d643b21e5ed54ab9da5b8adcb81c510c141 \n",
            "\r  0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\r                                          \r\n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n",
            "purge_analysis_df:   0% 0/2 [00:00<?, ?it/s]None\n",
            "('version',)                                                                                                     1.0\n",
            "('device',)                                                                                     torch.device('cuda')\n",
            "('seed',)                                                                                                 1482555873\n",
            "('num_iterations',)                                                                                               42\n",
            "('dataset',)                                                                                  covid-19-lung-ct-scans\n",
            "                                                                                         ...                        \n",
            "('train_on_batch_kwargs', 'is_return_results_every_t')                                                         False\n",
            "('train_on_batch_kwargs', 'is_checking_after_callback_after_t')                                                False\n",
            "('learn_code',)                                                    self.model.train()\\n\\ndef loss_fn(outputs, tar...\n",
            "('log_packs', 'classification_error', 'log')                                        self.classification_error.item()\n",
            "('log_packs', 'classification_error', 'at_data_pack')                                                       ['test']\n",
            "Length: 62, dtype: object\n",
            "\n",
            "FILTER\n",
            "{\"('version',)\": 1.0, \"('device',)\": \"torch.device('cuda')\", \"('seed',)\": 1482555873, \"('num_iterations',)\": 42, \"('dataset',)\": 'covid-19-lung-ct-scans', \"('batch_size',)\": 33, \"('before_DatasetLearningTrainable_setup_code',)\": 'def data_loader_fn(dataset, train, batch_size, partial_num=-1):\\n    \\n    transform = []\\n    transform.append(transforms.Grayscale(3))\\n    transform.append(transforms.Resize((32, 32)))\\n    transform.append(transforms.ToTensor())\\n\\n    target_transform = []\\n    target_transform.append(\\n        transforms.Lambda(\\n            lambda idx: utils.np_idx2onehot(idx, 2)\\n        )\\n    )\\n\\n    dataset = datasets.ImageFolder(\\n        f\\'{os.environ.get(\"DATA_DIR\")}/{dataset}\\',\\n        transform=transforms.Compose(transform),\\n        target_transform=transforms.Compose(target_transform)\\n    )\\n    train_size = int(0.8 * len(dataset))\\n    test_size = len(dataset) - train_size\\n    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\\n\\n    if train:\\n        data_subset = train_dataset\\n    else:\\n        data_subset = test_dataset\\n\\n    return DataLoader(\\n        data_subset,\\n        batch_size=batch_size,\\n        num_workers=1,\\n        pin_memory=True,\\n        shuffle=True,\\n        drop_last=True,\\n    )', \"('data_packs', 'train', 'data_loader')\": \"data_loader_fn(\\n    dataset=self.config['dataset'],\\n    train=True,\\n    batch_size=self.config['batch_size'],\\n)\", \"('data_packs', 'train', 'do')\": \"['learn']\", \"('data_packs', 'test', 'data_loader')\": \"data_loader_fn(\\n    dataset=self.config['dataset'],\\n    train=False,\\n    batch_size=self.config['batch_size'],\\n    # debug\\n    # partial_num=100,\\n)\", \"('data_packs', 'test', 'do')\": \"['predict']\", \"('predictive_coding',)\": False, \"('PCTrainer_kwargs', 'update_x_at')\": 'all', \"('PCTrainer_kwargs', 'optimizer_x_fn')\": 'SGD', \"('PCTrainer_kwargs', 'optimizer_x_kwargs', 'lr')\": 0.5, \"('PCTrainer_kwargs', 'x_lr_discount')\": 0.5, \"('PCTrainer_kwargs', 'x_lr_amplifier')\": 1.0, \"('PCTrainer_kwargs', 'update_p_at')\": 'all', \"('PCTrainer_kwargs', 'optimizer_p_fn')\": 'Adam', \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'lr')\": 0.0001, \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')\": 0.01, \"('PCTrainer_kwargs', 'T')\": 16, \"('PCTrainer_kwargs', 'plot_progress_at')\": '[]', \"('model', 'acf')\": 'torch.nn.ReLU', \"('model', 'model_type_order')\": \"['Weights', 'PCLayer', 'Acf', 'MaxPool']\", \"('model', 'cnn_layers', 'cnn_0', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'in_channels')\": 3, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'out_channels')\": 64, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'kernel_size')\": 5, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'padding')\": 2, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'bias')\": False, \"('model', 'cnn_layers', 'cnn_1', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'in_channels')\": 64, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'out_channels')\": 128, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'kernel_size')\": 3, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'padding')\": 1, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'bias')\": False, \"('model', 'cnn_layers', 'cnn_2', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'in_channels')\": 128, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'out_channels')\": 256, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'kernel_size')\": 3, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'padding')\": 1, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'bias')\": False, \"('model', 'linear_layers', 'linear_0', 'fn')\": 'torch.nn.Linear', \"('model', 'linear_layers', 'linear_0', 'kwargs', 'in_features')\": 4096, \"('model', 'linear_layers', 'linear_0', 'kwargs', 'out_features')\": 512, \"('model', 'linear_layers', 'linear_0', 'kwargs', 'bias')\": True, \"('model', 'linear_layers', 'last', 'fn')\": 'torch.nn.Linear', \"('model', 'linear_layers', 'last', 'kwargs', 'in_features')\": 512, \"('model', 'linear_layers', 'last', 'kwargs', 'out_features')\": 10, \"('model', 'linear_layers', 'last', 'kwargs', 'bias')\": True, \"('model_creation_code',)\": '# import\\nimport predictive_coding as pc\\nimport torch.optim as optim\\nimport aai_utils as u\\n\\n# create model\\nself.model = u.create_model(\\n    self.config[\\'predictive_coding\\'],\\n    **self.config[\\'model\\'],\\n    pt_model_path=f\\'{os.environ.get(\"PT_MODEL_DIR\")}/pt_rbp.pth\\',\\n    trainable_layers=4,\\n).to(self.device)\\n\\n# create pc_trainer kwargs\\nself.config[\\'PCTrainer_kwargs\\'][\\'optimizer_x_fn\\']=eval(\\n    \\'optim.{}\\'.format(self.config[\\'PCTrainer_kwargs\\'][\\'optimizer_x_fn\\'])\\n)\\nself.config[\\'PCTrainer_kwargs\\'][\\'optimizer_p_fn\\']=eval(\\n    \\'optim.{}\\'.format(self.config[\\'PCTrainer_kwargs\\'][\\'optimizer_p_fn\\'])\\n)\\nself.config[\\'PCTrainer_kwargs\\'][\\'plot_progress_at\\']=eval(\\n    self.config[\\'PCTrainer_kwargs\\'][\\'plot_progress_at\\']\\n)\\n\\n# create pc_trainer\\nself.pc_trainer = pc.PCTrainer(\\n    self.model,\\n    **self.config[\\'PCTrainer_kwargs\\'],\\n)', \"('predict_code',)\": '\\nself.model.eval()\\nprediction = self.model(data)\\nself.classification_error = utils.get_classification_error(\\n    prediction, target\\n)', \"('train_on_batch_kwargs', 'is_log_progress')\": False, \"('train_on_batch_kwargs', 'is_return_results_every_t')\": False, \"('train_on_batch_kwargs', 'is_checking_after_callback_after_t')\": False, \"('learn_code',)\": \"self.model.train()\\n\\ndef loss_fn(outputs, target):\\n    return (outputs - target).pow(2).sum() * 0.5\\n\\nself.pc_trainer.train_on_batch(\\n    data, loss_fn,\\n    loss_fn_kwargs={\\n        'target': target,\\n    },\\n    **self.config['train_on_batch_kwargs'],\\n)\\n\\ncurr_working_dir = os.getcwd()\\nmodel_filename = 'pt_rbp.pth'\\n\\ncurr_model_path = os.path.join(curr_working_dir, model_filename)\\ntorch.save(self.model.state_dict(), curr_model_path)\\n\\nfinal_model_path = os.path.join(os.environ.get('MODEL_DIR'), model_filename)\\nshutil.copy(curr_model_path, final_model_path)\", \"('log_packs', 'classification_error', 'log')\": 'self.classification_error.item()', \"('log_packs', 'classification_error', 'at_data_pack')\": \"['test']\"}\n",
            "\n",
            "# WARNING (analysis_utils): You have zero trial on a config.\n",
            "\n",
            "purge_analysis_df:  50% 1/2 [00:00<00:00, 73.39it/s]None\n",
            "('version',)                                                                                                     1.0\n",
            "('device',)                                                                                     torch.device('cuda')\n",
            "('seed',)                                                                                                 1482555873\n",
            "('num_iterations',)                                                                                               42\n",
            "('dataset',)                                                                                  covid-19-lung-ct-scans\n",
            "                                                                                         ...                        \n",
            "('train_on_batch_kwargs', 'is_return_results_every_t')                                                         False\n",
            "('train_on_batch_kwargs', 'is_checking_after_callback_after_t')                                                False\n",
            "('learn_code',)                                                    self.model.train()\\n\\ndef loss_fn(outputs, tar...\n",
            "('log_packs', 'classification_error', 'log')                                        self.classification_error.item()\n",
            "('log_packs', 'classification_error', 'at_data_pack')                                                       ['test']\n",
            "Length: 62, dtype: object\n",
            "\n",
            "FILTER\n",
            "{\"('version',)\": 1.0, \"('device',)\": \"torch.device('cuda')\", \"('seed',)\": 1482555873, \"('num_iterations',)\": 42, \"('dataset',)\": 'covid-19-lung-ct-scans', \"('batch_size',)\": 100, \"('before_DatasetLearningTrainable_setup_code',)\": 'def data_loader_fn(dataset, train, batch_size, partial_num=-1):\\n    \\n    transform = []\\n    transform.append(transforms.Grayscale(3))\\n    transform.append(transforms.Resize((32, 32)))\\n    transform.append(transforms.ToTensor())\\n\\n    target_transform = []\\n    target_transform.append(\\n        transforms.Lambda(\\n            lambda idx: utils.np_idx2onehot(idx, 2)\\n        )\\n    )\\n\\n    dataset = datasets.ImageFolder(\\n        f\\'{os.environ.get(\"DATA_DIR\")}/{dataset}\\',\\n        transform=transforms.Compose(transform),\\n        target_transform=transforms.Compose(target_transform)\\n    )\\n    train_size = int(0.8 * len(dataset))\\n    test_size = len(dataset) - train_size\\n    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\\n\\n    if train:\\n        data_subset = train_dataset\\n    else:\\n        data_subset = test_dataset\\n\\n    return DataLoader(\\n        data_subset,\\n        batch_size=batch_size,\\n        num_workers=1,\\n        pin_memory=True,\\n        shuffle=True,\\n        drop_last=True,\\n    )', \"('data_packs', 'train', 'data_loader')\": \"data_loader_fn(\\n    dataset=self.config['dataset'],\\n    train=True,\\n    batch_size=self.config['batch_size'],\\n)\", \"('data_packs', 'train', 'do')\": \"['learn']\", \"('data_packs', 'test', 'data_loader')\": \"data_loader_fn(\\n    dataset=self.config['dataset'],\\n    train=False,\\n    batch_size=self.config['batch_size'],\\n    # debug\\n    # partial_num=100,\\n)\", \"('data_packs', 'test', 'do')\": \"['predict']\", \"('predictive_coding',)\": False, \"('PCTrainer_kwargs', 'update_x_at')\": 'all', \"('PCTrainer_kwargs', 'optimizer_x_fn')\": 'SGD', \"('PCTrainer_kwargs', 'optimizer_x_kwargs', 'lr')\": 0.5, \"('PCTrainer_kwargs', 'x_lr_discount')\": 0.5, \"('PCTrainer_kwargs', 'x_lr_amplifier')\": 1.0, \"('PCTrainer_kwargs', 'update_p_at')\": 'all', \"('PCTrainer_kwargs', 'optimizer_p_fn')\": 'Adam', \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'lr')\": 0.0001, \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')\": 0.01, \"('PCTrainer_kwargs', 'T')\": 16, \"('PCTrainer_kwargs', 'plot_progress_at')\": '[]', \"('model', 'acf')\": 'torch.nn.ReLU', \"('model', 'model_type_order')\": \"['Weights', 'PCLayer', 'Acf', 'MaxPool']\", \"('model', 'cnn_layers', 'cnn_0', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'in_channels')\": 3, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'out_channels')\": 64, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'kernel_size')\": 5, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'padding')\": 2, \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'bias')\": False, \"('model', 'cnn_layers', 'cnn_1', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'in_channels')\": 64, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'out_channels')\": 128, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'kernel_size')\": 3, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'padding')\": 1, \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'bias')\": False, \"('model', 'cnn_layers', 'cnn_2', 'fn')\": 'torch.nn.Conv2d', \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'in_channels')\": 128, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'out_channels')\": 256, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'kernel_size')\": 3, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'stride')\": 1, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'padding')\": 1, \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'bias')\": False, \"('model', 'linear_layers', 'linear_0', 'fn')\": 'torch.nn.Linear', \"('model', 'linear_layers', 'linear_0', 'kwargs', 'in_features')\": 4096, \"('model', 'linear_layers', 'linear_0', 'kwargs', 'out_features')\": 512, \"('model', 'linear_layers', 'linear_0', 'kwargs', 'bias')\": True, \"('model', 'linear_layers', 'last', 'fn')\": 'torch.nn.Linear', \"('model', 'linear_layers', 'last', 'kwargs', 'in_features')\": 512, \"('model', 'linear_layers', 'last', 'kwargs', 'out_features')\": 10, \"('model', 'linear_layers', 'last', 'kwargs', 'bias')\": True, \"('model_creation_code',)\": '# import\\nimport predictive_coding as pc\\nimport torch.optim as optim\\nimport aai_utils as u\\n\\n# create model\\nself.model = u.create_model(\\n    self.config[\\'predictive_coding\\'],\\n    **self.config[\\'model\\'],\\n    pt_model_path=f\\'{os.environ.get(\"PT_MODEL_DIR\")}/pt_rbp.pth\\',\\n    trainable_layers=4,\\n).to(self.device)\\n\\n# create pc_trainer kwargs\\nself.config[\\'PCTrainer_kwargs\\'][\\'optimizer_x_fn\\']=eval(\\n    \\'optim.{}\\'.format(self.config[\\'PCTrainer_kwargs\\'][\\'optimizer_x_fn\\'])\\n)\\nself.config[\\'PCTrainer_kwargs\\'][\\'optimizer_p_fn\\']=eval(\\n    \\'optim.{}\\'.format(self.config[\\'PCTrainer_kwargs\\'][\\'optimizer_p_fn\\'])\\n)\\nself.config[\\'PCTrainer_kwargs\\'][\\'plot_progress_at\\']=eval(\\n    self.config[\\'PCTrainer_kwargs\\'][\\'plot_progress_at\\']\\n)\\n\\n# create pc_trainer\\nself.pc_trainer = pc.PCTrainer(\\n    self.model,\\n    **self.config[\\'PCTrainer_kwargs\\'],\\n)', \"('predict_code',)\": '\\nself.model.eval()\\nprediction = self.model(data)\\nself.classification_error = utils.get_classification_error(\\n    prediction, target\\n)', \"('train_on_batch_kwargs', 'is_log_progress')\": False, \"('train_on_batch_kwargs', 'is_return_results_every_t')\": False, \"('train_on_batch_kwargs', 'is_checking_after_callback_after_t')\": False, \"('learn_code',)\": \"self.model.train()\\n\\ndef loss_fn(outputs, target):\\n    return (outputs - target).pow(2).sum() * 0.5\\n\\nself.pc_trainer.train_on_batch(\\n    data, loss_fn,\\n    loss_fn_kwargs={\\n        'target': target,\\n    },\\n    **self.config['train_on_batch_kwargs'],\\n)\\n\\ncurr_working_dir = os.getcwd()\\nmodel_filename = 'pt_rbp.pth'\\n\\ncurr_model_path = os.path.join(curr_working_dir, model_filename)\\ntorch.save(self.model.state_dict(), curr_model_path)\\n\\nfinal_model_path = os.path.join(os.environ.get('MODEL_DIR'), model_filename)\\nshutil.copy(curr_model_path, final_model_path)\", \"('log_packs', 'classification_error', 'log')\": 'self.classification_error.item()', \"('log_packs', 'classification_error', 'at_data_pack')\": \"['test']\"}\n",
            "\n",
            "# WARNING (analysis_utils): You have zero trial on a config.\n",
            "\n",
            "\n",
            "# WARNING (analysis_utils): You have indexed in total zero trials.\n",
            "\n",
            "\n",
            "# WARNING (analysis_utils): You have missing trials on \n",
            "{   \"('PCTrainer_kwargs', 'T')\": [16],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_fn')\": ['Adam'],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'lr')\": [0.0001],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')\": [0.01],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_x_fn')\": ['SGD'],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_x_kwargs', 'lr')\": [0.5],\n",
            "    \"('PCTrainer_kwargs', 'plot_progress_at')\": ['[]'],\n",
            "    \"('PCTrainer_kwargs', 'update_p_at')\": ['all'],\n",
            "    \"('PCTrainer_kwargs', 'update_x_at')\": ['all'],\n",
            "    \"('PCTrainer_kwargs', 'x_lr_amplifier')\": [1.0],\n",
            "    \"('PCTrainer_kwargs', 'x_lr_discount')\": [0.5],\n",
            "    \"('batch_size',)\": [33, 100],\n",
            "    \"('before_DatasetLearningTrainable_setup_code',)\": [   'def '\n",
            "                                                           'data_loader_fn(dataset, '\n",
            "                                                           'train, batch_size, '\n",
            "                                                           'partial_num=-1):\\n'\n",
            "                                                           '    \\n'\n",
            "                                                           '    transform = '\n",
            "                                                           '[]\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.Grayscale(3))\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.Resize((32, '\n",
            "                                                           '32)))\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.ToTensor())\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    '\n",
            "                                                           'target_transform = '\n",
            "                                                           '[]\\n'\n",
            "                                                           '    '\n",
            "                                                           'target_transform.append(\\n'\n",
            "                                                           '        '\n",
            "                                                           'transforms.Lambda(\\n'\n",
            "                                                           '            lambda '\n",
            "                                                           'idx: '\n",
            "                                                           'utils.np_idx2onehot(idx, '\n",
            "                                                           '2)\\n'\n",
            "                                                           '        )\\n'\n",
            "                                                           '    )\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    dataset = '\n",
            "                                                           'datasets.ImageFolder(\\n'\n",
            "                                                           '        '\n",
            "                                                           'f\\'{os.environ.get(\"DATA_DIR\")}/{dataset}\\',\\n'\n",
            "                                                           '        '\n",
            "                                                           'transform=transforms.Compose(transform),\\n'\n",
            "                                                           '        '\n",
            "                                                           'target_transform=transforms.Compose(target_transform)\\n'\n",
            "                                                           '    )\\n'\n",
            "                                                           '    train_size = '\n",
            "                                                           'int(0.8 * '\n",
            "                                                           'len(dataset))\\n'\n",
            "                                                           '    test_size = '\n",
            "                                                           'len(dataset) - '\n",
            "                                                           'train_size\\n'\n",
            "                                                           '    train_dataset, '\n",
            "                                                           'test_dataset = '\n",
            "                                                           'torch.utils.data.random_split(dataset, '\n",
            "                                                           '[train_size, '\n",
            "                                                           'test_size])\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    if train:\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset = '\n",
            "                                                           'train_dataset\\n'\n",
            "                                                           '    else:\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset = '\n",
            "                                                           'test_dataset\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    return '\n",
            "                                                           'DataLoader(\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset,\\n'\n",
            "                                                           '        '\n",
            "                                                           'batch_size=batch_size,\\n'\n",
            "                                                           '        '\n",
            "                                                           'num_workers=1,\\n'\n",
            "                                                           '        '\n",
            "                                                           'pin_memory=True,\\n'\n",
            "                                                           '        '\n",
            "                                                           'shuffle=True,\\n'\n",
            "                                                           '        '\n",
            "                                                           'drop_last=True,\\n'\n",
            "                                                           '    )'],\n",
            "    \"('data_packs', 'test', 'data_loader')\": [   'data_loader_fn(\\n'\n",
            "                                                 '    '\n",
            "                                                 \"dataset=self.config['dataset'],\\n\"\n",
            "                                                 '    train=False,\\n'\n",
            "                                                 '    '\n",
            "                                                 \"batch_size=self.config['batch_size'],\\n\"\n",
            "                                                 '    # debug\\n'\n",
            "                                                 '    # partial_num=100,\\n'\n",
            "                                                 ')'],\n",
            "    \"('data_packs', 'test', 'do')\": [\"['predict']\"],\n",
            "    \"('data_packs', 'train', 'data_loader')\": [   'data_loader_fn(\\n'\n",
            "                                                  '    '\n",
            "                                                  \"dataset=self.config['dataset'],\\n\"\n",
            "                                                  '    train=True,\\n'\n",
            "                                                  '    '\n",
            "                                                  \"batch_size=self.config['batch_size'],\\n\"\n",
            "                                                  ')'],\n",
            "    \"('data_packs', 'train', 'do')\": [\"['learn']\"],\n",
            "    \"('dataset',)\": ['covid-19-lung-ct-scans'],\n",
            "    \"('device',)\": [\"torch.device('cuda')\"],\n",
            "    \"('learn_code',)\": [   'self.model.train()\\n'\n",
            "                           '\\n'\n",
            "                           'def loss_fn(outputs, target):\\n'\n",
            "                           '    return (outputs - target).pow(2).sum() * 0.5\\n'\n",
            "                           '\\n'\n",
            "                           'self.pc_trainer.train_on_batch(\\n'\n",
            "                           '    data, loss_fn,\\n'\n",
            "                           '    loss_fn_kwargs={\\n'\n",
            "                           \"        'target': target,\\n\"\n",
            "                           '    },\\n'\n",
            "                           \"    **self.config['train_on_batch_kwargs'],\\n\"\n",
            "                           ')\\n'\n",
            "                           '\\n'\n",
            "                           'curr_working_dir = os.getcwd()\\n'\n",
            "                           \"model_filename = 'pt_rbp.pth'\\n\"\n",
            "                           '\\n'\n",
            "                           'curr_model_path = os.path.join(curr_working_dir, '\n",
            "                           'model_filename)\\n'\n",
            "                           'torch.save(self.model.state_dict(), '\n",
            "                           'curr_model_path)\\n'\n",
            "                           '\\n'\n",
            "                           'final_model_path = '\n",
            "                           \"os.path.join(os.environ.get('MODEL_DIR'), \"\n",
            "                           'model_filename)\\n'\n",
            "                           'shutil.copy(curr_model_path, final_model_path)'],\n",
            "    \"('log_packs', 'classification_error', 'at_data_pack')\": [\"['test']\"],\n",
            "    \"('log_packs', 'classification_error', 'log')\": [   'self.classification_error.item()'],\n",
            "    \"('model', 'acf')\": ['torch.nn.ReLU'],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'in_channels')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'kernel_size')\": [5],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'out_channels')\": [64],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'padding')\": [2],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'in_channels')\": [64],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'kernel_size')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'out_channels')\": [128],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'padding')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'in_channels')\": [128],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'kernel_size')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'out_channels')\": [256],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'padding')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'linear_layers', 'last', 'fn')\": ['torch.nn.Linear'],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'bias')\": [True],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'in_features')\": [512],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'out_features')\": [10],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'fn')\": ['torch.nn.Linear'],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'bias')\": [True],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'in_features')\": [4096],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'out_features')\": [512],\n",
            "    \"('model', 'model_type_order')\": [   \"['Weights', 'PCLayer', 'Acf', \"\n",
            "                                         \"'MaxPool']\"],\n",
            "    \"('model_creation_code',)\": [   '# import\\n'\n",
            "                                    'import predictive_coding as pc\\n'\n",
            "                                    'import torch.optim as optim\\n'\n",
            "                                    'import aai_utils as u\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create model\\n'\n",
            "                                    'self.model = u.create_model(\\n'\n",
            "                                    \"    self.config['predictive_coding'],\\n\"\n",
            "                                    \"    **self.config['model'],\\n\"\n",
            "                                    '    '\n",
            "                                    'pt_model_path=f\\'{os.environ.get(\"PT_MODEL_DIR\")}/pt_rbp.pth\\',\\n'\n",
            "                                    '    trainable_layers=4,\\n'\n",
            "                                    ').to(self.device)\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create pc_trainer kwargs\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['optimizer_x_fn']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"'optim.{}'.format(self.config['PCTrainer_kwargs']['optimizer_x_fn'])\\n\"\n",
            "                                    ')\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['optimizer_p_fn']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"'optim.{}'.format(self.config['PCTrainer_kwargs']['optimizer_p_fn'])\\n\"\n",
            "                                    ')\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['plot_progress_at']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"self.config['PCTrainer_kwargs']['plot_progress_at']\\n\"\n",
            "                                    ')\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create pc_trainer\\n'\n",
            "                                    'self.pc_trainer = pc.PCTrainer(\\n'\n",
            "                                    '    self.model,\\n'\n",
            "                                    \"    **self.config['PCTrainer_kwargs'],\\n\"\n",
            "                                    ')'],\n",
            "    \"('num_iterations',)\": [42],\n",
            "    \"('predict_code',)\": [   '\\n'\n",
            "                             'self.model.eval()\\n'\n",
            "                             'prediction = self.model(data)\\n'\n",
            "                             'self.classification_error = '\n",
            "                             'utils.get_classification_error(\\n'\n",
            "                             '    prediction, target\\n'\n",
            "                             ')'],\n",
            "    \"('predictive_coding',)\": [False],\n",
            "    \"('seed',)\": [1482555873],\n",
            "    \"('train_on_batch_kwargs', 'is_checking_after_callback_after_t')\": [False],\n",
            "    \"('train_on_batch_kwargs', 'is_log_progress')\": [False],\n",
            "    \"('train_on_batch_kwargs', 'is_return_results_every_t')\": [False],\n",
            "    \"('version',)\": [1.0]}\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/prospective-configuration/analysis_v1.py\", line 289, in <module>\n",
            "    analysis_df = au.purge_analysis_df_with_config_dicts(\n",
            "  File \"/content/prospective-configuration/analysis_utils.py\", line 1308, in purge_analysis_df_with_config_dicts\n",
            "    purged_analysis_df = purge_analysis_df(\n",
            "  File \"/content/prospective-configuration/analysis_utils.py\", line 1288, in purge_analysis_df\n",
            "    analysis_df.dataframe = pd.concat(rows)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 372, in concat\n",
            "    op = _Concatenator(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 429, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-01\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.1}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.1})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwoJ9HDR0zG",
        "outputId": "045edfb6-166a-4c74-8c8c-85a0e7e30dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-01; UID: c68df9b9376dab61af527124d210c5b94aedc5aa \n",
            "                                          \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.01}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.01})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuB578f5SGDU",
        "outputId": "05d94ae9-4911-4d40-b352-0ea578b16055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-001; UID: c68df9b9376dab61af527124d210c5b94aedc5aa \n",
            "                                          \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-0001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P2azafHSSdI",
        "outputId": "3e6500e0-31d2-43a9-b298-06fb2a3bd22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-0001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-00001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.0001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.0001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CukV8Wo6ScXW",
        "outputId": "8d777afd-9f90-46f5-c775-71edb04241dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-00001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-000001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.00001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.00001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pebX0FAXwYhQ",
        "outputId": "4e021805-f82e-49b8-f45d-f3b5a868dde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-000001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve-0000001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.000001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.000001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='Rule',height=5, aspect=1).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5pOhMNMwyTj",
        "outputId": "23ca8f7a-4d73-417e-c847-3cae8c9e672a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve-0000001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error pc_learning_rate \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC'}),au.filter_dataframe_by_dict(df,{'Rule':'BP'})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='pc_learning_rate',aspect=1.5).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUFaYUxsSqU3",
        "outputId": "c79d7825-772a-4c70-eab8-bf87a7a01e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve_batch_iteration_0001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error pc_learning_rate batch_size \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"print(df.columns)\"\\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='batch_size',aspect=1.5).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHMYKganzXPe",
        "outputId": "92415731-f41a-4819-fe63-55985f9c729a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve_batch_iteration_0001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n",
            "GROUP: :   0% 0/1 [00:00<?, ?it/s]Index(['logdir', 'test__classification_error-along-training_iteration', 'T',\n",
            "       'Optimizer for learn', 'pc_learning_rate', 'weight_decay',\n",
            "       'Optimizer for inference', 'Inference rate',\n",
            "       'PCTrainer_kwargs: plot_progress_at', 'update_p_at',\n",
            "       'PCTrainer_kwargs: update_x_at', 'x_lr_amplifier', 'x_lr_discount',\n",
            "       'batch_size', 'before_DatasetLearningTrainable_setup_code',\n",
            "       'data_packs: test: data_loader', 'data_packs: test: do',\n",
            "       'data_packs: train: data_loader', 'data_packs: train: do', 'Dataset',\n",
            "       'device', 'learn_code', 'log_packs: classification_error: at_data_pack',\n",
            "       'log_packs: classification_error: log', 'acf',\n",
            "       'model: cnn_layers: cnn_0: fn',\n",
            "       'model: cnn_layers: cnn_0: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_0: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_0: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_0: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_1: fn',\n",
            "       'model: cnn_layers: cnn_1: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_1: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_1: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_1: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_2: fn',\n",
            "       'model: cnn_layers: cnn_2: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_2: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_2: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_2: kwargs: stride',\n",
            "       'model: linear_layers: last: fn',\n",
            "       'model: linear_layers: last: kwargs: bias',\n",
            "       'model: linear_layers: last: kwargs: in_features',\n",
            "       'model: linear_layers: last: kwargs: out_features',\n",
            "       'model: linear_layers: linear_0: fn',\n",
            "       'model: linear_layers: linear_0: kwargs: bias',\n",
            "       'model: linear_layers: linear_0: kwargs: in_features',\n",
            "       'model: linear_layers: linear_0: kwargs: out_features',\n",
            "       'model_type_order', 'model_creation_code', 'num_iterations',\n",
            "       'partial_num', 'predict_code', 'PC', 'seed',\n",
            "       'train_on_batch_kwargs: is_checking_after_callback_after_t',\n",
            "       'train_on_batch_kwargs: is_log_progress',\n",
            "       'train_on_batch_kwargs: is_return_results_every_t', 'version'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve_batch_iteration_00001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error pc_learning_rate batch_size \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"print(df.columns)\"\\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.0001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.0001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='batch_size',aspect=1.5).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkEjm7rCzi-i",
        "outputId": "ecd5bc8a-01b9-4896-f070-cff037391747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve_batch_iteration_00001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n",
            "GROUP: :   0% 0/1 [00:00<?, ?it/s]Index(['logdir', 'test__classification_error-along-training_iteration', 'T',\n",
            "       'Optimizer for learn', 'pc_learning_rate', 'weight_decay',\n",
            "       'Optimizer for inference', 'Inference rate',\n",
            "       'PCTrainer_kwargs: plot_progress_at', 'update_p_at',\n",
            "       'PCTrainer_kwargs: update_x_at', 'x_lr_amplifier', 'x_lr_discount',\n",
            "       'batch_size', 'before_DatasetLearningTrainable_setup_code',\n",
            "       'data_packs: test: data_loader', 'data_packs: test: do',\n",
            "       'data_packs: train: data_loader', 'data_packs: train: do', 'Dataset',\n",
            "       'device', 'learn_code', 'log_packs: classification_error: at_data_pack',\n",
            "       'log_packs: classification_error: log', 'acf',\n",
            "       'model: cnn_layers: cnn_0: fn',\n",
            "       'model: cnn_layers: cnn_0: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_0: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_0: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_0: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_1: fn',\n",
            "       'model: cnn_layers: cnn_1: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_1: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_1: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_1: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_2: fn',\n",
            "       'model: cnn_layers: cnn_2: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_2: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_2: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_2: kwargs: stride',\n",
            "       'model: linear_layers: last: fn',\n",
            "       'model: linear_layers: last: kwargs: bias',\n",
            "       'model: linear_layers: last: kwargs: in_features',\n",
            "       'model: linear_layers: last: kwargs: out_features',\n",
            "       'model: linear_layers: linear_0: fn',\n",
            "       'model: linear_layers: linear_0: kwargs: bias',\n",
            "       'model: linear_layers: linear_0: kwargs: in_features',\n",
            "       'model: linear_layers: linear_0: kwargs: out_features',\n",
            "       'model_type_order', 'model_creation_code', 'num_iterations',\n",
            "       'partial_num', 'predict_code', 'PC', 'seed',\n",
            "       'train_on_batch_kwargs: is_checking_after_callback_after_t',\n",
            "       'train_on_batch_kwargs: is_log_progress',\n",
            "       'train_on_batch_kwargs: is_return_results_every_t', 'version'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve_batch_iteration_000001\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error pc_learning_rate batch_size \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"print(df.columns)\"\\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.00001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.00001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='batch_size',aspect=1.5).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZcU5FRJznS_",
        "outputId": "2328db94-5d00-424d-ec39-7c75d134d430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve_batch_iteration_000001; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n",
            "GROUP: :   0% 0/1 [00:00<?, ?it/s]Index(['logdir', 'test__classification_error-along-training_iteration', 'T',\n",
            "       'Optimizer for learn', 'pc_learning_rate', 'weight_decay',\n",
            "       'Optimizer for inference', 'Inference rate',\n",
            "       'PCTrainer_kwargs: plot_progress_at', 'update_p_at',\n",
            "       'PCTrainer_kwargs: update_x_at', 'x_lr_amplifier', 'x_lr_discount',\n",
            "       'batch_size', 'before_DatasetLearningTrainable_setup_code',\n",
            "       'data_packs: test: data_loader', 'data_packs: test: do',\n",
            "       'data_packs: train: data_loader', 'data_packs: train: do', 'Dataset',\n",
            "       'device', 'learn_code', 'log_packs: classification_error: at_data_pack',\n",
            "       'log_packs: classification_error: log', 'acf',\n",
            "       'model: cnn_layers: cnn_0: fn',\n",
            "       'model: cnn_layers: cnn_0: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_0: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_0: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_0: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_0: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_1: fn',\n",
            "       'model: cnn_layers: cnn_1: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_1: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_1: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_1: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_1: kwargs: stride',\n",
            "       'model: cnn_layers: cnn_2: fn',\n",
            "       'model: cnn_layers: cnn_2: kwargs: bias',\n",
            "       'model: cnn_layers: cnn_2: kwargs: in_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: kernel_size',\n",
            "       'model: cnn_layers: cnn_2: kwargs: out_channels',\n",
            "       'model: cnn_layers: cnn_2: kwargs: padding',\n",
            "       'model: cnn_layers: cnn_2: kwargs: stride',\n",
            "       'model: linear_layers: last: fn',\n",
            "       'model: linear_layers: last: kwargs: bias',\n",
            "       'model: linear_layers: last: kwargs: in_features',\n",
            "       'model: linear_layers: last: kwargs: out_features',\n",
            "       'model: linear_layers: linear_0: fn',\n",
            "       'model: linear_layers: linear_0: kwargs: bias',\n",
            "       'model: linear_layers: linear_0: kwargs: in_features',\n",
            "       'model: linear_layers: linear_0: kwargs: out_features',\n",
            "       'model_type_order', 'model_creation_code', 'num_iterations',\n",
            "       'partial_num', 'predict_code', 'PC', 'seed',\n",
            "       'train_on_batch_kwargs: is_checking_after_callback_after_t',\n",
            "       'train_on_batch_kwargs: is_log_progress',\n",
            "       'train_on_batch_kwargs: is_return_results_every_t', 'version'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve_batch_iteration\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"compress_plot('test__classification_error','training_iteration')\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-f \\\n",
        "--source-include-columns training_iteration Rule seed test__classification_error pc_learning_rate batch_size \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"print(df.columns)\"\\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"df=pd.concat([au.filter_dataframe_by_dict(df,{'Rule':'PC','pc_learning_rate':0.0001}),au.filter_dataframe_by_dict(df,{'Rule':'BP','pc_learning_rate':0.0001})])\" \\\n",
        "\"df=au.extract_plot(df,'test__classification_error','training_iteration')\" \\\n",
        "\"g=au.nature_relplot_curve(data=df,x='training_iteration',y='test__classification_error',hue='Rule',style='batch_size',aspect=1.5).set_titles('Iteration vs Test Classification Error').set_axis_labels('Iteration','Test Classification Error', fontsize=14).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"au.nature_post(g,is_grid=False)\" \\\n",
        "\"plt.savefig('fig4-f.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR4MwxlOxrzV",
        "outputId": "ce56b5f0-ea90-46aa-8f67-a5bba021bb81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve_batch_iteration; UID: 061150bad6b0b119b9d2874f9e11e30e47d48c26 \n",
            "\r  0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\rget_analysis_df:   0% 0/4 [00:00<?, ?it/s]\r                                          \r\n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n",
            "purge_analysis_df:   0% 0/2 [00:00<?, ?it/s]\n",
            "# WARNING (analysis_utils): You have zero trial on a config.\n",
            "\n",
            "purge_analysis_df:  50% 1/2 [00:00<00:00, 74.76it/s]\n",
            "# WARNING (analysis_utils): You have zero trial on a config.\n",
            "\n",
            "\n",
            "# WARNING (analysis_utils): You have indexed in total zero trials.\n",
            "\n",
            "\n",
            "# WARNING (analysis_utils): You have missing trials on \n",
            "{   \"('PCTrainer_kwargs', 'T')\": [16],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_fn')\": ['Adam'],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'lr')\": [0.0001],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_p_kwargs', 'weight_decay')\": [0.01],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_x_fn')\": ['SGD'],\n",
            "    \"('PCTrainer_kwargs', 'optimizer_x_kwargs', 'lr')\": [0.5],\n",
            "    \"('PCTrainer_kwargs', 'plot_progress_at')\": ['[]'],\n",
            "    \"('PCTrainer_kwargs', 'update_p_at')\": ['all'],\n",
            "    \"('PCTrainer_kwargs', 'update_x_at')\": ['all'],\n",
            "    \"('PCTrainer_kwargs', 'x_lr_amplifier')\": [1.0],\n",
            "    \"('PCTrainer_kwargs', 'x_lr_discount')\": [0.5],\n",
            "    \"('batch_size',)\": [33, 100],\n",
            "    \"('before_DatasetLearningTrainable_setup_code',)\": [   'def '\n",
            "                                                           'data_loader_fn(dataset, '\n",
            "                                                           'train, batch_size, '\n",
            "                                                           'partial_num=-1):\\n'\n",
            "                                                           '    \\n'\n",
            "                                                           '    transform = '\n",
            "                                                           '[]\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.Grayscale(3))\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.Resize((32, '\n",
            "                                                           '32)))\\n'\n",
            "                                                           '    '\n",
            "                                                           'transform.append(transforms.ToTensor())\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    '\n",
            "                                                           'target_transform = '\n",
            "                                                           '[]\\n'\n",
            "                                                           '    '\n",
            "                                                           'target_transform.append(\\n'\n",
            "                                                           '        '\n",
            "                                                           'transforms.Lambda(\\n'\n",
            "                                                           '            lambda '\n",
            "                                                           'idx: '\n",
            "                                                           'utils.np_idx2onehot(idx, '\n",
            "                                                           '2)\\n'\n",
            "                                                           '        )\\n'\n",
            "                                                           '    )\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    dataset = '\n",
            "                                                           'datasets.ImageFolder(\\n'\n",
            "                                                           '        '\n",
            "                                                           'f\\'{os.environ.get(\"DATA_DIR\")}/{dataset}\\',\\n'\n",
            "                                                           '        '\n",
            "                                                           'transform=transforms.Compose(transform),\\n'\n",
            "                                                           '        '\n",
            "                                                           'target_transform=transforms.Compose(target_transform)\\n'\n",
            "                                                           '    )\\n'\n",
            "                                                           '    train_size = '\n",
            "                                                           'int(0.8 * '\n",
            "                                                           'len(dataset))\\n'\n",
            "                                                           '    test_size = '\n",
            "                                                           'len(dataset) - '\n",
            "                                                           'train_size\\n'\n",
            "                                                           '    train_dataset, '\n",
            "                                                           'test_dataset = '\n",
            "                                                           'torch.utils.data.random_split(dataset, '\n",
            "                                                           '[train_size, '\n",
            "                                                           'test_size])\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    if train:\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset = '\n",
            "                                                           'train_dataset\\n'\n",
            "                                                           '    else:\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset = '\n",
            "                                                           'test_dataset\\n'\n",
            "                                                           '\\n'\n",
            "                                                           '    return '\n",
            "                                                           'DataLoader(\\n'\n",
            "                                                           '        '\n",
            "                                                           'data_subset,\\n'\n",
            "                                                           '        '\n",
            "                                                           'batch_size=batch_size,\\n'\n",
            "                                                           '        '\n",
            "                                                           'num_workers=1,\\n'\n",
            "                                                           '        '\n",
            "                                                           'pin_memory=True,\\n'\n",
            "                                                           '        '\n",
            "                                                           'shuffle=True,\\n'\n",
            "                                                           '        '\n",
            "                                                           'drop_last=True,\\n'\n",
            "                                                           '    )'],\n",
            "    \"('data_packs', 'test', 'data_loader')\": [   'data_loader_fn(\\n'\n",
            "                                                 '    '\n",
            "                                                 \"dataset=self.config['dataset'],\\n\"\n",
            "                                                 '    train=False,\\n'\n",
            "                                                 '    '\n",
            "                                                 \"batch_size=self.config['batch_size'],\\n\"\n",
            "                                                 '    # debug\\n'\n",
            "                                                 '    # partial_num=100,\\n'\n",
            "                                                 ')'],\n",
            "    \"('data_packs', 'test', 'do')\": [\"['predict']\"],\n",
            "    \"('data_packs', 'train', 'data_loader')\": [   'data_loader_fn(\\n'\n",
            "                                                  '    '\n",
            "                                                  \"dataset=self.config['dataset'],\\n\"\n",
            "                                                  '    train=True,\\n'\n",
            "                                                  '    '\n",
            "                                                  \"batch_size=self.config['batch_size'],\\n\"\n",
            "                                                  ')'],\n",
            "    \"('data_packs', 'train', 'do')\": [\"['learn']\"],\n",
            "    \"('dataset',)\": ['covid-19-lung-ct-scans'],\n",
            "    \"('device',)\": [\"torch.device('cuda')\"],\n",
            "    \"('learn_code',)\": [   'self.model.train()\\n'\n",
            "                           '\\n'\n",
            "                           'def loss_fn(outputs, target):\\n'\n",
            "                           '    return (outputs - target).pow(2).sum() * 0.5\\n'\n",
            "                           '\\n'\n",
            "                           'self.pc_trainer.train_on_batch(\\n'\n",
            "                           '    data, loss_fn,\\n'\n",
            "                           '    loss_fn_kwargs={\\n'\n",
            "                           \"        'target': target,\\n\"\n",
            "                           '    },\\n'\n",
            "                           \"    **self.config['train_on_batch_kwargs'],\\n\"\n",
            "                           ')\\n'\n",
            "                           '\\n'\n",
            "                           'curr_working_dir = os.getcwd()\\n'\n",
            "                           \"model_filename = 'pt_rbp.pth'\\n\"\n",
            "                           '\\n'\n",
            "                           'curr_model_path = os.path.join(curr_working_dir, '\n",
            "                           'model_filename)\\n'\n",
            "                           'torch.save(self.model.state_dict(), '\n",
            "                           'curr_model_path)\\n'\n",
            "                           '\\n'\n",
            "                           'final_model_path = '\n",
            "                           \"os.path.join(os.environ.get('MODEL_DIR'), \"\n",
            "                           'model_filename)\\n'\n",
            "                           'shutil.copy(curr_model_path, final_model_path)'],\n",
            "    \"('log_packs', 'classification_error', 'at_data_pack')\": [\"['test']\"],\n",
            "    \"('log_packs', 'classification_error', 'log')\": [   'self.classification_error.item()'],\n",
            "    \"('model', 'acf')\": ['torch.nn.ReLU'],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'in_channels')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'kernel_size')\": [5],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'out_channels')\": [64],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'padding')\": [2],\n",
            "    \"('model', 'cnn_layers', 'cnn_0', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'in_channels')\": [64],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'kernel_size')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'out_channels')\": [128],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'padding')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_1', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'fn')\": ['torch.nn.Conv2d'],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'bias')\": [False],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'in_channels')\": [128],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'kernel_size')\": [3],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'out_channels')\": [256],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'padding')\": [1],\n",
            "    \"('model', 'cnn_layers', 'cnn_2', 'kwargs', 'stride')\": [1],\n",
            "    \"('model', 'linear_layers', 'last', 'fn')\": ['torch.nn.Linear'],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'bias')\": [True],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'in_features')\": [512],\n",
            "    \"('model', 'linear_layers', 'last', 'kwargs', 'out_features')\": [10],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'fn')\": ['torch.nn.Linear'],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'bias')\": [True],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'in_features')\": [4096],\n",
            "    \"('model', 'linear_layers', 'linear_0', 'kwargs', 'out_features')\": [512],\n",
            "    \"('model', 'model_type_order')\": [   \"['Weights', 'PCLayer', 'Acf', \"\n",
            "                                         \"'MaxPool']\"],\n",
            "    \"('model_creation_code',)\": [   '# import\\n'\n",
            "                                    'import predictive_coding as pc\\n'\n",
            "                                    'import torch.optim as optim\\n'\n",
            "                                    'import aai_utils as u\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create model\\n'\n",
            "                                    'self.model = u.create_model(\\n'\n",
            "                                    \"    self.config['predictive_coding'],\\n\"\n",
            "                                    \"    **self.config['model'],\\n\"\n",
            "                                    '    '\n",
            "                                    'pt_model_path=f\\'{os.environ.get(\"PT_MODEL_DIR\")}/pt_rbp.pth\\',\\n'\n",
            "                                    '    trainable_layers=4,\\n'\n",
            "                                    ').to(self.device)\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create pc_trainer kwargs\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['optimizer_x_fn']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"'optim.{}'.format(self.config['PCTrainer_kwargs']['optimizer_x_fn'])\\n\"\n",
            "                                    ')\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['optimizer_p_fn']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"'optim.{}'.format(self.config['PCTrainer_kwargs']['optimizer_p_fn'])\\n\"\n",
            "                                    ')\\n'\n",
            "                                    \"self.config['PCTrainer_kwargs']['plot_progress_at']=eval(\\n\"\n",
            "                                    '    '\n",
            "                                    \"self.config['PCTrainer_kwargs']['plot_progress_at']\\n\"\n",
            "                                    ')\\n'\n",
            "                                    '\\n'\n",
            "                                    '# create pc_trainer\\n'\n",
            "                                    'self.pc_trainer = pc.PCTrainer(\\n'\n",
            "                                    '    self.model,\\n'\n",
            "                                    \"    **self.config['PCTrainer_kwargs'],\\n\"\n",
            "                                    ')'],\n",
            "    \"('num_iterations',)\": [42],\n",
            "    \"('predict_code',)\": [   '\\n'\n",
            "                             'self.model.eval()\\n'\n",
            "                             'prediction = self.model(data)\\n'\n",
            "                             'self.classification_error = '\n",
            "                             'utils.get_classification_error(\\n'\n",
            "                             '    prediction, target\\n'\n",
            "                             ')'],\n",
            "    \"('predictive_coding',)\": [False],\n",
            "    \"('seed',)\": [1482555873],\n",
            "    \"('train_on_batch_kwargs', 'is_checking_after_callback_after_t')\": [False],\n",
            "    \"('train_on_batch_kwargs', 'is_log_progress')\": [False],\n",
            "    \"('train_on_batch_kwargs', 'is_return_results_every_t')\": [False],\n",
            "    \"('version',)\": [1.0]}\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/prospective-configuration/analysis_v1.py\", line 289, in <module>\n",
            "    analysis_df = au.purge_analysis_df_with_config_dicts(\n",
            "  File \"/content/prospective-configuration/analysis_utils.py\", line 1304, in purge_analysis_df_with_config_dicts\n",
            "    purged_analysis_df = purge_analysis_df(\n",
            "  File \"/content/prospective-configuration/analysis_utils.py\", line 1284, in purge_analysis_df\n",
            "    analysis_df.dataframe = pd.concat(rows)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 372, in concat\n",
            "    op = _Concatenator(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\", line 429, in __init__\n",
            "    raise ValueError(\"No objects to concatenate\")\n",
            "ValueError: No objects to concatenate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python analysis_v1.py \\\n",
        "-t \"curve_batch_error\" \\\n",
        "-l \"$RESULTS_DIR/$EXP_NAME\" \\\n",
        "-m \"df['test__classification_error'].min()\" \\\n",
        "-f \"./aai-experiments/$EXP_NAME/base-rbp.yaml\" \"./aai-experiments/$EXP_NAME/base-ppc.yaml\" \\\n",
        "--fig-name fig4-i \\\n",
        "--source-include-columns Rule seed batch_size \"Min of test__classification_error\" \\\n",
        "-v \\\n",
        "\"import analysis_utils as au\" \\\n",
        "\"import matplotlib.pyplot as plt\" \\\n",
        "\"df=au.nature_pre(df)\" \\\n",
        "\"g=au.nature_relplot(data=df,y='Min of test__classification_error',x='batch_size',hue='Rule',style='Rule', height=5, aspect=1).set(xscale='log').set_titles('Batch Size vs Test Classification Error').set_axis_labels('Batch Size','Test Classification Error',fontsize=10).tight_layout(w_pad=0)\" \\\n",
        "\"plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\" \\\n",
        "\"g.set_xticklabels(size=14)\" \\\n",
        "\"g.set_yticklabels(size=14)\" \\\n",
        "\"plt.savefig('fig4-i.png')\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8HCZX1Nx7Vk",
        "outputId": "f54cbcf1-1baf-4c37-c8db-9f48aba809d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " TITLE: curve_batch_error; UID: 589079f85404f944510a597e7722c118dd05b069 \n",
            "                                           \n",
            "# WARNING (__main__): Config yaml loaded. You can safely make changes to the yaml now.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ./aai-experiments/$EXP_NAME/* $ANALYSIS_DIR"
      ],
      "metadata": {
        "id": "V9SZzhi9kiGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BSxT_aUklsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "BT8SKKYSw16R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvSZ4wr7eQHq",
        "outputId": "a49ae52c-8cac-4e85-a022-2fa5cb2d5912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 319 bytes | 63.00 KiB/s, done.\n",
            "From https://github.com/kajanan1212/prospective-configuration\n",
            "   33ff2e2..6fa864f  kajanan/create-experiments-folder-for-aai -> origin/kajanan/create-experiments-folder-for-aai\n",
            "Updating 33ff2e2..6fa864f\n",
            "Fast-forward\n",
            " analysis_utils.py | 1 \u001b[32m+\u001b[m\n",
            " 1 file changed, 1 insertion(+)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYzB5WlreuH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b43056-4f58-4c8f-85b5-96ab8058237d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd ../"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a24Xq_EUW-__"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WZfwtBUfxug8",
        "t_RC7PCUxqg6",
        "fVTXzU0yxmSZ",
        "fjFfTFn-xcS5",
        "KOGsjNONxQlU",
        "dSIBZQrHxWNO",
        "QH3r3q7qwxL2",
        "BT8SKKYSw16R"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}